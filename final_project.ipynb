{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled38.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdz74//+4ur3PmJW8FnGo0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/ml_hw/blob/master/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mcnl3d4t16E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "976b63d9-e410-4d8c-c35c-4c2831ba11f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktBc033kvgpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "346b7f81-bed4-42cd-952c-0f18a8bdc0fb"
      },
      "source": [
        "!unzip '/content/drive/My Drive/jigsaw-toxic-comment-train.csv.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/jigsaw-toxic-comment-train.csv.zip\n",
            "  inflating: jigsaw-toxic-comment-train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49azZAoIwKS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "72a127e8-8b0a-4a40-ba14-c00b4eb2df25"
      },
      "source": [
        "import pandas as pd\n",
        "from string import punctuation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from statsmodels.graphics.mosaicplot import mosaic\n",
        "import statistics \n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from collections import Counter\n",
        "import seaborn as sns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p01Q0kQYTjgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa9d3594-ef8b-4cbb-a7ed-be7ac0817ec2"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#print(stopwords.words('english'))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyK6JPXbSPYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_train = pd.read_csv('jigsaw-toxic-comment-train.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Wuig06p16B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "4106a27e-4fb2-484b-f983-e1b5ee4441d5"
      },
      "source": [
        "my_train.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 223549 entries, 0 to 223548\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             223549 non-null  object\n",
            " 1   comment_text   223549 non-null  object\n",
            " 2   toxic          223549 non-null  int64 \n",
            " 3   severe_toxic   223549 non-null  int64 \n",
            " 4   obscene        223549 non-null  int64 \n",
            " 5   threat         223549 non-null  int64 \n",
            " 6   insult         223549 non-null  int64 \n",
            " 7   identity_hate  223549 non-null  int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 13.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML57pGG1T3d1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4fa92a56-5967-4d31-fb90-4d6ea9d76f80"
      },
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "my_train.head(10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the tools well.  · talk \"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic sever_toxic obscene insult</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contrary to those of DuLithgow</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  \\\n",
              "0  0000997932d777bf   \n",
              "1  000103f0d9cfb60f   \n",
              "2  000113f07ec002fd   \n",
              "3  0001b41b1c6bb37e   \n",
              "4  0001d958c54c6e35   \n",
              "5  00025465d4725e87   \n",
              "6  0002bcb3da6cb337   \n",
              "7  00031b1e95af7921   \n",
              "8  00037261f536c51d   \n",
              "9  00040093b2687caa   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         comment_text  \\\n",
              "0  Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27                                                                                                                                                                                                                                                                                                                                                                            \n",
              "1  D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "2  Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
              "4  You, sir, are my hero. Any chance you remember what page that's on?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "5  \"\\n\\nCongratulations from me as well, use the tools well.  · talk \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "6  COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
              "7  Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "8  Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169                                                                                                                                                             \n",
              "9  alignment on this subject and which are contrary to those of DuLithgow                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "\n",
              "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
              "0  0      0             0        0       0       0               \n",
              "1  0      0             0        0       0       0               \n",
              "2  0      0             0        0       0       0               \n",
              "3  0      0             0        0       0       0               \n",
              "4  0      0             0        0       0       0               \n",
              "5  0      0             0        0       0       0               \n",
              "6  1      1             1        0       1       0               \n",
              "7  0      0             0        0       0       0               \n",
              "8  0      0             0        0       0       0               \n",
              "9  0      0             0        0       0       0               \n",
              "\n",
              "                            cluster  cluster_num  \n",
              "0  non_toxic                         40           \n",
              "1  non_toxic                         40           \n",
              "2  non_toxic                         40           \n",
              "3  non_toxic                         40           \n",
              "4  non_toxic                         40           \n",
              "5  non_toxic                         40           \n",
              "6  toxic sever_toxic obscene insult  15           \n",
              "7  non_toxic                         40           \n",
              "8  non_toxic                         40           \n",
              "9  non_toxic                         40           "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7JFUmTqu6Nh",
        "colab_type": "text"
      },
      "source": [
        "### **Анализ всех дополнительных колонок тональности (как проявляется тот или иной тип токсичности, как в данных это представлено, какие есть пограничные случаи)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pAWFlW2wR0J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "773d7fae-581e-4ddb-fe4a-2f6579578915"
      },
      "source": [
        "len(my_train.loc[my_train['toxic']==1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXeHxzTh8vS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "08106f5e-7b72-49c7-95e8-340245b305b3"
      },
      "source": [
        "def max_tox_len(toxic_type):\n",
        "  toxic_type_df = my_train.loc[my_train[toxic_type] == 1]\n",
        "  len_list = [len(sent) for sent in toxic_type_df['comment_text']]\n",
        "  return max(len_list)\n",
        "\n",
        "\n",
        "print('toxic', max_tox_len('toxic'))\n",
        "print('severe_toxic', max_tox_len('severe_toxic'))\n",
        "print('obscene', max_tox_len('obscene'))\n",
        "print('threat', max_tox_len('threat'))\n",
        "print('insult', max_tox_len('insult'))\n",
        "print('identity_hate', max_tox_len('identity_hate'))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic 5000\n",
            "severe_toxic 5000\n",
            "obscene 5000\n",
            "threat 5000\n",
            "insult 5000\n",
            "identity_hate 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HicLvCes-oBO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ac445937-19cb-43ab-f733-d6eea9de9231"
      },
      "source": [
        "def max_none_tox_len(none_toxic_type):\n",
        "  toxic_type_df = my_train.loc[my_train[none_toxic_type] == 0]\n",
        "  len_list = [len(sent) for sent in toxic_type_df['comment_text']]\n",
        "  return max(len_list)\n",
        "\n",
        "\n",
        "print('toxic', max_none_tox_len('toxic'))\n",
        "print('severe_toxic', max_none_tox_len('severe_toxic'))\n",
        "print('obscene', max_none_tox_len('obscene'))\n",
        "print('threat', max_none_tox_len('threat'))\n",
        "print('insult', max_none_tox_len('insult'))\n",
        "print('identity_hate', max_none_tox_len('identity_hate'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic 5000\n",
            "severe_toxic 5000\n",
            "obscene 5000\n",
            "threat 5000\n",
            "insult 5000\n",
            "identity_hate 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5sZjo68YfTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Получается совсем не информативно, попробую измерить среднее"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izVxpJ3Xe0IC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "28d2c88e-cfc6-4d75-b6e5-32b3f91c3b2b"
      },
      "source": [
        "def mean_tox_len(toxic_type):\n",
        "  toxic_type_df = my_train.loc[my_train[toxic_type] == 1]\n",
        "  len_list = [len(sent) for sent in toxic_type_df['comment_text']]\n",
        "  return statistics.mean(len_list)\n",
        "\n",
        "\n",
        "print('toxic', mean_tox_len('toxic'))\n",
        "print('severe_toxic', mean_tox_len('severe_toxic'))\n",
        "print('obscene', mean_tox_len('obscene'))\n",
        "print('threat', mean_tox_len('threat'))\n",
        "print('insult', mean_tox_len('insult'))\n",
        "print('identity_hate', mean_tox_len('identity_hate'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic 280.60409652076316\n",
            "severe_toxic 505.4566768603466\n",
            "obscene 280.9517298187809\n",
            "threat 316.9100145137881\n",
            "insult 272.2064755838641\n",
            "identity_hate 314.43882853094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zSBef7Lgwso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#тут немного более информативно, severe_toxic явно выделяется, например. Попробую взять не-токсичные:"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ra9G1EIf73p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1b1127ee-a68f-41a6-bff4-f70f181994e8"
      },
      "source": [
        "def mean_none_tox_len(none_toxic_type):\n",
        "  toxic_type_df = my_train.loc[my_train[none_toxic_type] == 0]\n",
        "  len_list = [len(sent) for sent in toxic_type_df['comment_text']]\n",
        "  return statistics.mean(len_list)\n",
        "\n",
        "\n",
        "print('toxic', mean_none_tox_len('toxic'))\n",
        "print('severe_toxic', mean_none_tox_len('severe_toxic'))\n",
        "print('obscene', mean_none_tox_len('obscene'))\n",
        "print('threat', mean_none_tox_len('threat'))\n",
        "print('insult', mean_none_tox_len('insult'))\n",
        "print('identity_hate', mean_none_tox_len('identity_hate'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic 402.6911779981698\n",
            "severe_toxic 389.999386245583\n",
            "obscene 397.33287608379965\n",
            "threat 391.2418065153011\n",
            "insult 397.34023416334895\n",
            "identity_hate 391.7447929838506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07pp06YKgprO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Попробую выделить списки слов, характерных для конкретных типов."
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCMOhy-TwqM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sents):\n",
        "    words = []\n",
        "    for sent in sents:\n",
        "      for word in sent.split():\n",
        "        words.append(word.strip(string.punctuation))\n",
        "    words = [word for word in words if word]\n",
        "    \n",
        "    return words"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flIuKI4t2uBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  это просто на будущее более удобное разделение данных по типам\n",
        "toxic_df = my_train.loc[my_train['toxic'] == 1]\n",
        "severe_toxic_df = my_train.loc[my_train['severe_toxic'] == 1]\n",
        "obscene_df =  my_train.loc[my_train['obscene'] == 1]\n",
        "threat_df = my_train.loc[my_train['threat'] == 1]\n",
        "insult_df = my_train.loc[my_train['insult'] == 1]\n",
        "identity_hate_df = my_train.loc[my_train['identity_hate'] == 1]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nsmMW4uWTML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "870b83eb-0995-4736-df47-14be437bbfe7"
      },
      "source": [
        "stoplist = stopwords.words('english')\n",
        "for w in ['would', 'page', 'wikipedia', 'want', 'think', 'time']:\n",
        "  stoplist.append(w)\n",
        "'would' in stoplist"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dQKD5Xkv_uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def freq_words(toxic_type, n):\n",
        "  toxic_type_df = my_train.loc[my_train[toxic_type] == 1]\n",
        "  length = len(toxic_type_df)\n",
        "  counter = Counter(tokenize(toxic_type_df['comment_text']))\n",
        "  frequent_dict = {key:val for key, val in counter.items() if val > length*n and \\\n",
        "                   key.lower() not in stoplist}\n",
        "\n",
        "  return frequent_dict"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_xII2Ra1sOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ff26ebff-e89e-4c7f-de81-426b028ebd1f"
      },
      "source": [
        "freq_words('toxic', 0.1)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DIE': 2760,\n",
              " 'FUCK': 5952,\n",
              " 'NIGGER': 3397,\n",
              " 'SUCK': 2675,\n",
              " 'ass': 2240,\n",
              " 'fuck': 6151,\n",
              " 'fucking': 2766,\n",
              " 'gay': 2192,\n",
              " 'know': 2523,\n",
              " 'like': 4149,\n",
              " 'shit': 2971}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3cOSDDX18zt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d4410fa-263f-4303-96ea-581bb646c2db"
      },
      "source": [
        "freq_words('severe_toxic', 0.1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ADMINS': 200,\n",
              " 'ANAL': 342,\n",
              " 'ASS': 762,\n",
              " 'Ass': 271,\n",
              " 'BASTARD': 205,\n",
              " 'BITCH': 644,\n",
              " 'BITCH!!FUCK': 310,\n",
              " 'BLOCK': 266,\n",
              " 'BOT': 217,\n",
              " 'Bitch': 293,\n",
              " 'BunkSteve': 278,\n",
              " 'COCK': 442,\n",
              " 'COCKSUCKER': 494,\n",
              " 'COCKSUCKING': 267,\n",
              " 'CUNT': 819,\n",
              " 'CUNTS': 241,\n",
              " 'Chester': 261,\n",
              " 'CriminalWar': 279,\n",
              " 'DAMN': 377,\n",
              " 'DICK': 331,\n",
              " 'DIE': 1565,\n",
              " 'DIE!FUK': 402,\n",
              " 'DOG': 363,\n",
              " 'EAT': 204,\n",
              " 'FACK': 232,\n",
              " 'FAGGOT': 605,\n",
              " 'FAGS': 207,\n",
              " 'FAT': 243,\n",
              " 'FUCK': 3088,\n",
              " 'FUCKER': 523,\n",
              " 'FUCKING': 1084,\n",
              " 'Fuck': 1051,\n",
              " 'Fucking': 212,\n",
              " 'GAY': 250,\n",
              " 'GO': 223,\n",
              " 'Go': 924,\n",
              " 'HOMELAND': 229,\n",
              " 'HUGE': 421,\n",
              " 'KILL': 630,\n",
              " 'MEXICANS': 358,\n",
              " 'MOTHERFUCKER': 253,\n",
              " 'MOTHERFUCKERDIE': 287,\n",
              " 'MOTHJER': 489,\n",
              " 'MUST': 562,\n",
              " 'MarcolFuck': 260,\n",
              " 'NIGGER': 808,\n",
              " 'NIGGERJEW': 424,\n",
              " 'NIGGERS': 393,\n",
              " 'Nigger': 367,\n",
              " 'Notrhbysouthbanof': 228,\n",
              " 'OFFFUCK': 360,\n",
              " \"Pro-Assad.Hanibal911You're\": 345,\n",
              " 'RAPE': 362,\n",
              " 'SECURITYFUCK': 227,\n",
              " 'SHIT': 1508,\n",
              " 'SHUT': 364,\n",
              " 'SUCK': 2253,\n",
              " 'TRAITOR': 405,\n",
              " 'U': 939,\n",
              " 'USELESS': 224,\n",
              " 'VANDAL': 406,\n",
              " \"YOU!!'FUCK\": 312,\n",
              " 'ancestryFuck-off-Jewish': 207,\n",
              " 'ass': 1299,\n",
              " 'ass!Fuck': 277,\n",
              " 'asshole': 320,\n",
              " 'bastard': 407,\n",
              " 'bitch': 780,\n",
              " 'bitches.fuck': 333,\n",
              " 'cock': 366,\n",
              " 'cocks': 235,\n",
              " 'cunt': 321,\n",
              " 'dick': 290,\n",
              " 'dickhead': 330,\n",
              " 'faggot': 1237,\n",
              " 'fat': 296,\n",
              " 'fuck': 3279,\n",
              " 'fucked': 199,\n",
              " 'fucking': 750,\n",
              " 'fucksex': 624,\n",
              " 'gay': 484,\n",
              " 'get': 228,\n",
              " 'going': 344,\n",
              " 'hi': 201,\n",
              " 'know': 222,\n",
              " 'like': 501,\n",
              " 'little': 292,\n",
              " 'mother': 413,\n",
              " 'niggas': 340,\n",
              " 'nigger': 599,\n",
              " 'nigger!Dumbass': 215,\n",
              " 'penis/////Small': 249,\n",
              " 'piece': 363,\n",
              " 'pussy': 303,\n",
              " 'shit': 900,\n",
              " 'stupid': 374,\n",
              " 'suck': 521,\n",
              " 'sucks': 698,\n",
              " 'u': 733,\n",
              " 'veggietales': 212,\n",
              " 'yourselfgo': 621}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP0s_SL4T0EJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "57dd28d1-2b4d-4d16-9365-9d136ecca4fc"
      },
      "source": [
        "freq_words('obscene', 0.1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CUNT': 1440,\n",
              " 'DICKS': 1223,\n",
              " 'DIE': 1468,\n",
              " 'FUCK': 5940,\n",
              " 'FUCKING': 1592,\n",
              " 'Fuck': 1961,\n",
              " 'Go': 1240,\n",
              " 'NIGGER': 2990,\n",
              " 'SHIT': 1688,\n",
              " 'SUCK': 2535,\n",
              " 'U': 1319,\n",
              " 'ass': 2121,\n",
              " 'bitch': 1511,\n",
              " 'fuck': 6073,\n",
              " 'fucking': 2651,\n",
              " 'get': 1248,\n",
              " 'know': 1376,\n",
              " 'like': 2061,\n",
              " 'shit': 2623,\n",
              " 'stupid': 1264,\n",
              " 'u': 1599}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vg61H3MVd0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "2df8e953-f6f2-4644-c6d0-09c09a8abb48"
      },
      "source": [
        "freq_words('threat', 0.1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BAN': 131,\n",
              " 'BLANK': 94,\n",
              " 'BLOCK': 150,\n",
              " 'DI': 90,\n",
              " 'DIE': 1055,\n",
              " 'DIE!FUK': 310,\n",
              " 'Die': 89,\n",
              " 'EDIE': 90,\n",
              " 'FUCKIN': 82,\n",
              " 'FUCKING': 74,\n",
              " 'FoReVeR': 76,\n",
              " 'FooL': 73,\n",
              " \"I'm\": 73,\n",
              " 'JIM': 157,\n",
              " 'KILL': 526,\n",
              " 'LiVe': 76,\n",
              " 'MUST': 478,\n",
              " 'NIGGGERS': 123,\n",
              " 'PaTHeTiC': 76,\n",
              " 'RVV': 96,\n",
              " 'ReSPeCT': 76,\n",
              " 'SuPeRTR0LL': 149,\n",
              " 'TALK': 101,\n",
              " 'TRAITOR': 313,\n",
              " 'VANDAL': 314,\n",
              " 'WALES': 156,\n",
              " 'ass': 753,\n",
              " 'balls': 92,\n",
              " 'bitch': 81,\n",
              " 'decapitate': 84,\n",
              " 'die': 120,\n",
              " 'fuck': 102,\n",
              " 'fucking': 176,\n",
              " 'get': 84,\n",
              " 'going': 383,\n",
              " 'kill': 275,\n",
              " 'like': 69,\n",
              " 'murder': 109,\n",
              " 'rip': 87,\n",
              " 'shit': 96,\n",
              " 'tiny': 83,\n",
              " 'u': 70,\n",
              " 'you.I': 81}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIHKCzQpaM6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "da6e17ec-2ac7-4283-db04-89a950a3c39c"
      },
      "source": [
        "freq_words('insult', 0.1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CUNT': 1134,\n",
              " 'DIE': 1465,\n",
              " 'FAT': 1565,\n",
              " 'FUCK': 4238,\n",
              " 'FUCKING': 1516,\n",
              " 'Fuck': 1179,\n",
              " 'Go': 1235,\n",
              " 'JEW': 1246,\n",
              " 'NIGGER': 3033,\n",
              " 'SUCK': 2380,\n",
              " 'U': 1279,\n",
              " 'ass': 1882,\n",
              " 'bitch': 1458,\n",
              " 'faggot': 1718,\n",
              " 'fuck': 4670,\n",
              " 'fucking': 2252,\n",
              " 'gay': 1154,\n",
              " 'hi': 1345,\n",
              " 'know': 1361,\n",
              " 'like': 2052,\n",
              " 'moron': 1474,\n",
              " 'nigger': 1593,\n",
              " 'shit': 2025,\n",
              " 'stupid': 1447,\n",
              " 'u': 1525}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9fnKqkka0Yb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "93fd7594-4d58-4b5e-b31d-c92bfe3d54bc"
      },
      "source": [
        "freq_words('identity_hate', 0.1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ass': 271,\n",
              " 'Bitch': 286,\n",
              " 'BunkSteve': 278,\n",
              " 'CUNT': 595,\n",
              " 'DIE': 772,\n",
              " 'FAGGOT': 555,\n",
              " 'FAT': 1314,\n",
              " 'FRANCE': 217,\n",
              " 'FUCK': 696,\n",
              " 'FUCKING': 449,\n",
              " 'GAY': 681,\n",
              " 'HATE': 228,\n",
              " 'HUGE': 422,\n",
              " 'JEW': 1245,\n",
              " 'KILL': 313,\n",
              " 'MEXICANS': 358,\n",
              " 'NIGGER': 3098,\n",
              " 'NIGGERJEW': 424,\n",
              " 'NIGGERS': 1113,\n",
              " 'Nigger': 507,\n",
              " 'Please!Nigga': 383,\n",
              " 'SUCK': 551,\n",
              " 'TOMMY2010': 227,\n",
              " 'ass': 327,\n",
              " 'bitch': 324,\n",
              " 'fag': 246,\n",
              " 'faggot': 724,\n",
              " 'fuck': 751,\n",
              " 'fucking': 499,\n",
              " 'gay': 1334,\n",
              " 'like': 451,\n",
              " 'nigga': 227,\n",
              " 'niggas': 359,\n",
              " 'nigger': 1594,\n",
              " 'nigger!Dumbass': 215,\n",
              " 'shit': 358,\n",
              " 'stupid': 425,\n",
              " 'sucks!!!!!!!!!!!U.S.A': 223,\n",
              " 'u': 302}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx5Hi0P17Q64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#посмотрим, сколько частотных слов вообще в каком типе получилось"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFrX4pbwbAdd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a869d361-0d41-46d8-cb6e-062a25a7cf63"
      },
      "source": [
        "print('severe_toxic', len(freq_words('severe_toxic', 0.1)))\n",
        "print('toxic', len(freq_words('toxic', 0.1)))\n",
        "print('obscene', len(freq_words('obscene', 0.1)))\n",
        "print('threat', len(freq_words('threat', 0.1)))\n",
        "print('insult', len(freq_words('insult', 0.1)))\n",
        "print('identity_hate', len(freq_words('identity_hate', 0.1)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "severe_toxic 101\n",
            "toxic 11\n",
            "obscene 21\n",
            "threat 43\n",
            "insult 25\n",
            "identity_hate 39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjUy93M_7afl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#и как они пересекаются между собой. Я полагаю, что uppercase так же несет в себе информацию о тональности, \n",
        "# и полагаю upper-lowercase разными словами."
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhM_Rl807fU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toxic_set = set(freq_words('toxic', 0.1).keys())\n",
        "severe_toxic_set = set(freq_words('severe_toxic', 0.1).keys())\n",
        "obscene_set = set(freq_words('obscene', 0.1).keys())\n",
        "threat_set = set(freq_words('threat', 0.1).keys())\n",
        "insult_set = set(freq_words('insult', 0.1).keys())\n",
        "identity_hate_set = set(freq_words('identity_hate', 0.1).keys())                                                 \n",
        "# как toxic пересекается с остальными"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3odf-0l_SQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9026bc7-c782-473e-ea7b-18157a1054df"
      },
      "source": [
        "toxic_set.intersection(severe_toxic_set, obscene_set, threat_set, insult_set, identity_hate_set)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DIE', 'ass', 'fuck', 'fucking', 'like', 'shit'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5GzRxOXA_rI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#И посмотрим, как они выделяются"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flu9s25dBC-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7309c985-730d-4c06-dbb1-31cfc501bf13"
      },
      "source": [
        "print('severe_toxic_set', severe_toxic_set.difference(toxic_set, obscene_set, threat_set, insult_set, identity_hate_set))\n",
        "print('toxic_set', toxic_set.difference(severe_toxic_set, obscene_set, threat_set, insult_set, identity_hate_set))\n",
        "print('threat_set', threat_set.difference(toxic_set, severe_toxic_set, obscene_set, insult_set, identity_hate_set))\n",
        "print('insult_set', insult_set.difference(toxic_set, obscene_set, threat_set, severe_toxic_set, identity_hate_set))\n",
        "print('identity_hate_set', identity_hate_set.difference(toxic_set, obscene_set, threat_set, insult_set, identity_hate_set))\n",
        "print('obscene_set', obscene_set.difference(toxic_set, identity_hate_set, threat_set, insult_set, identity_hate_set))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "severe_toxic_set {'CUNTS', 'veggietales', 'bitches.fuck', 'BITCH', 'MOTHERFUCKER', 'DICK', 'fat', 'Notrhbysouthbanof', 'MarcolFuck', 'BITCH!!FUCK', 'EAT', 'yourselfgo', 'COCKSUCKING', 'mother', 'sucks', \"Pro-Assad.Hanibal911You're\", 'ancestryFuck-off-Jewish', 'Fucking', 'COCK', 'BOT', 'Chester', 'GO', 'FUCKER', 'FAGS', 'ass!Fuck', 'CriminalWar', 'asshole', 'bastard', 'HOMELAND', 'little', 'cock', 'BASTARD', 'SHUT', 'OFFFUCK', 'ASS', \"YOU!!'FUCK\", 'suck', 'dick', 'MOTHERFUCKERDIE', 'MOTHJER', 'COCKSUCKER', 'RAPE', 'penis/////Small', 'dickhead', 'ADMINS', 'ANAL', 'piece', 'USELESS', 'fucksex', 'FACK', 'DAMN', 'DOG', 'SECURITYFUCK', 'fucked', 'cocks', 'pussy', 'cunt'}\n",
            "toxic_set set()\n",
            "threat_set {'kill', 'tiny', 'FUCKIN', \"I'm\", 'rip', 'FooL', 'JIM', 'DI', 'BAN', 'BLANK', 'RVV', 'decapitate', 'TALK', 'ReSPeCT', 'Die', 'you.I', 'balls', 'NIGGGERS', 'LiVe', 'die', 'EDIE', 'PaTHeTiC', 'murder', 'WALES', 'SuPeRTR0LL', 'FoReVeR'}\n",
            "insult_set {'moron'}\n",
            "identity_hate_set set()\n",
            "obscene_set {'DICKS', 'SHIT'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtejghhMDO7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#в severe_toxic просто больше слов, а вот threat можно заметить слова с верхним и нижним регистром в одном.\n",
        "# Попробую их тоже рассматривать как признак  и посчитать."
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKI8I2FmDokr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba08f492-5a22-4078-b57e-aa957a617790"
      },
      "source": [
        "re.findall(r'([A-Z]+[a-z]+[A-Z]+)|([a-z]+[A-Z]+[a-z]+)', 'HellO')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('HellO', '')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6YHn5ZOUMmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upper_lower_words(toxic_type):\n",
        "  len_list = []\n",
        "  token_list = []\n",
        "  toxic_type_df = my_train.loc[my_train[toxic_type] == 1]\n",
        "  length = len(toxic_type_df)\n",
        "  df_tokens = tokenize(toxic_type_df['comment_text'])\n",
        "  for token in df_tokens:\n",
        "    if len(re.findall(r'([A-Z]+[a-z]+[A-Z]+)|([a-z]+[A-Z]+[a-z]+)', token)) > 0:\n",
        "      len_list.append(len(token))\n",
        "      token_list.append(token)\n",
        "  return len_list"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adPwloKv4rXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#еще потом придумаю, но минималка какая-то вроде есть.\n",
        "# len_list = [len(sents) for sents in my_train['comment_text']]\n",
        "# punkt_len_list = [len(re.findall(r'[\\.,?!)\\\";}\\]\\*:@\\'\\({\\[]+', sents)) for sents in my_train['comment_text']]\n",
        "# upper_len_list = [len(re.findall(r'[A-Z]+', sents)) for sents in my_train['comment_text']]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8xF8DgxR_by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_toxic = \" \".join(my_train.loc[my_train['toxic'] == 1]['comment_text'])\n",
        "all_severe_toxic = \" \".join(my_train.loc[my_train['severe_toxic'] == 1]['comment_text'])\n",
        "all_obscene = \" \".join(my_train.loc[my_train['obscene'] == 1]['comment_text'])\n",
        "all_threat = \" \".join(my_train.loc[my_train['threat'] == 1]['comment_text'])\n",
        "all_insult = \" \".join(my_train.loc[my_train['insult'] == 1]['comment_text'])\n",
        "all_identity_hate = \" \".join(my_train.loc[my_train['identity_hate'] == 1]['comment_text'])                                  "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxE7aGhlarfl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9f9e01a9-e5e8-4f71-d4ce-912aa970395c"
      },
      "source": [
        "print('severe_toxic', sum(upper_lower_words('severe_toxic')))\n",
        "print('toxic', sum(upper_lower_words('toxic')))\n",
        "print('obscene', sum(upper_lower_words('obscene')))\n",
        "print('threat', sum(upper_lower_words('threat')))\n",
        "print('insult', sum(upper_lower_words('insult')))\n",
        "print('identity_hate', sum(upper_lower_words('identity_hate')))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "severe_toxic 19582\n",
            "toxic 56533\n",
            "obscene 36456\n",
            "threat 5047\n",
            "insult 31223\n",
            "identity_hate 9179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmOssIrf54i3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b6be89c8-a235-4bfe-a0f5-8bf7f6d79338"
      },
      "source": [
        "print('severe_toxic', sum(upper_lower_words('severe_toxic'))/len(all_severe_toxic))\n",
        "print('toxic', sum(upper_lower_words('toxic'))/len(all_toxic))\n",
        "print('obscene', sum(upper_lower_words('obscene'))/len(all_obscene))\n",
        "print('threat', sum(upper_lower_words('threat'))/len(all_threat))\n",
        "print('insult', sum(upper_lower_words('insult'))/len(all_insult))\n",
        "print('identity_hate', sum(upper_lower_words('identity_hate'))/len(all_identity_hate))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "severe_toxic 0.01970680318456787\n",
            "toxic 0.009388023988092638\n",
            "obscene 0.01065063967819035\n",
            "threat 0.02304155880916184\n",
            "insult 0.010110011090154048\n",
            "identity_hate 0.013745483188401023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAK8K0ecbINN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# И так же стоит посмотреть на пунктуацию"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPeIIITfcdxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def punkt_len(toxic_type):\n",
        "  final_len = 0\n",
        "  all_text = \" \".join(my_train.loc[my_train[toxic_type] == 1]['comment_text'])\n",
        "  all_punkt = re.findall(r'[\\.,?!)\\\";}\\]\\*:@\\'\\({\\[]+', all_text)\n",
        "  for punkt_peace in all_punkt:\n",
        "    final_len += len(punkt_peace)\n",
        "  return final_len\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUNgzEvX6tUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0cd82217-18ee-4ebc-dac7-822e45a46974"
      },
      "source": [
        "print('toxic', punkt_len('toxic'))\n",
        "print('severe_toxic', punkt_len('severe_toxic'))\n",
        "print('obscene', punkt_len('obscene'))\n",
        "print('threat', punkt_len('threat'))\n",
        "print('insult', punkt_len('insult'))\n",
        "print('identity_hate', punkt_len('identity_hate'))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic 269048\n",
            "severe_toxic 51662\n",
            "obscene 151698\n",
            "threat 16543\n",
            "insult 134153\n",
            "identity_hate 25735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRmR78XGeF10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "231813a5-f31c-47be-8f07-18c3dbedbcc6"
      },
      "source": [
        "print('toxic', punkt_len('toxic')/len(all_toxic))\n",
        "print('severe_toxic', punkt_len('severe_toxic')/len(all_severe_toxic))\n",
        "print('obscene', punkt_len('obscene')/len(all_obscene))\n",
        "print('threat', punkt_len('threat')/len(all_threat))\n",
        "print('insult', punkt_len('insult')/len(all_insult))\n",
        "print('identity_hate', punkt_len('identity_hate')/len(all_identity_hate))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic 0.04467884382481645\n",
            "severe_toxic 0.051991260653720006\n",
            "obscene 0.0443186509189741\n",
            "threat 0.07552536306319879\n",
            "insult 0.0434387572551464\n",
            "identity_hate 0.03853796817229549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dbw_FC5abNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgB5D9f0bGVt",
        "colab_type": "text"
      },
      "source": [
        "## **Бейзлайн модель из sklearn (векторайзер + модель) c подбором параметров в greed_search (как минимум 10 параметров) **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybnTY8INbJwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/mannefedov/hse_ml_m1/blob/master/1_intro_regression/pandas_regression.ipynb - регуляризация\n",
        "# тут и статистики есть!!\n",
        "\n",
        "#https://github.com/mannefedov/hse_ml_m1/blob/master/3_overfitting_validation/overfitting_validation.ipynb - permutation importance\n",
        "\n",
        "\n",
        "#ансамбли - https://github.com/DmitryKutsev/ml_hw/blob/master/hw5.ipynb\n",
        "\n",
        "#ох.."
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdgGDcyuFNe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "f8383179-76df-42af-8125-70b0238f1938"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\r\u001b[K     |███                             | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.15.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLV9twVjhQkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f834c8b1-5b77-4fc1-b62c-cf15d2ed2541"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "import warnings"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4it8RakKr7WS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer(max_features=1000, min_df=5, max_df=0.4, ngram_range=(1,2))\n",
        "X = cv.fit_transform(my_train['comment_text'])\n",
        "y = my_train['toxic']\n",
        "miniX = cv.fit_transform(my_train['comment_text'][:10000])\n",
        "miniy = my_train['toxic'][:10000]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL1OaPx4EgC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def scores(model):\n",
        "  ''' Функция для оценки моделей на тесте'''\n",
        "  \n",
        "  predicted = model.predict(X_test)\n",
        "  acc = accuracy_score(predicted, twenty_test.target)\n",
        "  micro_f1 = f1_score(predicted, twenty_test.target, average = 'micro')\n",
        "  micro_p = precision_score(predicted, twenty_test.target, average = 'micro')\n",
        "  micro_r = recall_score(predicted, twenty_test.target, average = 'micro')\n",
        "  macro_f1 = f1_score(predicted, twenty_test.target, average = 'macro')\n",
        "  macro_p = precision_score(predicted, twenty_test.target, average = 'macro')\n",
        "  macro_r = recall_score(predicted, twenty_test.target, average = 'macro')\n",
        "  print('acc={0:1.4f}'.format(acc))\n",
        "  print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
        "  print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZc7E2GXqunD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "miniX_train, miniX_test, miniy_train, miniy_test = train_test_split(miniX, miniy, random_state=42)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HepjStmrHds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# regressor = Lasso(alpha=1)\n",
        "# regressor.fit(X_train, y_train)\n",
        "# preds = regressor.predict(X_test)\n",
        "# mean_absolute_error(y_test, preds)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab3G07SA0B6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = LogisticRegression()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43R-qfiiinj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "parameter_grid = {'class_weight' : ['balanced', None],\n",
        "                  'penalty' : ['l2', 'l1'],\n",
        "                  'solver' : ['liblinear', 'saga'],\n",
        "                  'C' : [0.001, 0.01, 0.08],\n",
        "                  'max_iter': [2,10],\n",
        "                  'warm_start' : [False, True],\n",
        "                  'tol':[0.0001, 0.001],\n",
        "                  'l1_ratio': [0, 1],\n",
        "                  'verbose': [0, 1],\n",
        "                  'intercept_scaling': [1, 2]\n",
        "                 }\n",
        "\n",
        "grid_search = GridSearchCV(lr, param_grid=parameter_grid, cv=10, scoring='roc_auc')\n",
        "grid_search.fit(miniX_train, miniy_train)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2WBPSERHv6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6afb85eb-c539-4f9d-aa3c-4f8106d49693"
      },
      "source": [
        "print('Best score: {}'.format(grid_search.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search.best_params_))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.8934634778370368\n",
            "Best parameters: {'C': 0.08, 'class_weight': None, 'intercept_scaling': 1, 'l1_ratio': 0, 'max_iter': 10, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFWOc3bC3wYx",
        "colab_type": "text"
      },
      "source": [
        "## **Использование кластеризационного алгоритма для разделение по токсичности (оценивание нужно сделать по специальным метрикам)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZieNpk3kK_u7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "from sklearn.cluster import AffinityPropagation, MeanShift, AgglomerativeClustering\n",
        "from sklearn.decomposition import TruncatedSVD, NMF\n",
        "from sklearn.cluster import AffinityPropagation, AgglomerativeClustering, DBSCAN, \\\n",
        "                            KMeans, MiniBatchKMeans, Birch, MeanShift, SpectralClustering\n",
        "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, \\\n",
        "                            silhouette_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD, NMF\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_blobs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8YD78--4JGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_list = []\n",
        "for row in range(len(my_train)):\n",
        "  cluster = ''\n",
        "  if my_train['toxic'][row] == 1:\n",
        "    cluster = 'toxic'\n",
        "  if my_train['severe_toxic'][row]  == 1:\n",
        "    cluster += ' sever_toxic'\n",
        "  if my_train['obscene'][row]  == 1:\n",
        "    cluster += ' obscene'\n",
        "  if my_train['threat'][row]  == 1:\n",
        "    cluster += ' threat'\n",
        "  if my_train['insult'][row]  == 1:\n",
        "    cluster += ' insult'\n",
        "  if my_train['identity_hate'][row]  == 1:\n",
        "    cluster += ' identity_hate'\n",
        "  if cluster == '':\n",
        "    cluster = 'non_toxic'\n",
        "  cluster_list.append(cluster)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5NBy_24_Tf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "050b060f-49a3-4d8d-bf74-7012f13ecc7d"
      },
      "source": [
        "print(len(set(cluster_list)))\n",
        "cluster_list[:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['non_toxic', 'non_toxic', 'non_toxic', 'non_toxic', 'non_toxic']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw2jVjKQ9fJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "76f6c5c1-d610-411a-ad13-ce54116fc669"
      },
      "source": [
        "my_train['cluster'] = cluster_list\n",
        "my_train.head(6)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...    cluster\n",
              "0  0000997932d777bf  ...  non_toxic\n",
              "1  000103f0d9cfb60f  ...  non_toxic\n",
              "2  000113f07ec002fd  ...  non_toxic\n",
              "3  0001b41b1c6bb37e  ...  non_toxic\n",
              "4  0001d958c54c6e35  ...  non_toxic\n",
              "5  00025465d4725e87  ...  non_toxic\n",
              "\n",
              "[6 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eme8eTXlAS4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_clusters = list(set(my_train['cluster']))\n",
        "val = 0\n",
        "clusters_num_count = Counter()\n",
        "for i in list_of_clusters:\n",
        "  clusters_num_count[i] = val\n",
        "  val += 1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmnuONkMATA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_num_list = []\n",
        "for row in range(len(my_train)):\n",
        "  num = clusters_num_count[my_train['cluster'][row]]\n",
        "  cluster_num_list.append(num)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO9GDnJ0C0hJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "268b084b-fd2c-40e1-80a6-3c72ff331be5"
      },
      "source": [
        "my_train['cluster_num'] = cluster_num_list\n",
        "my_train.head(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic sever_toxic obscene insult</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... cluster_num\n",
              "0  0000997932d777bf  ...          40\n",
              "1  000103f0d9cfb60f  ...          40\n",
              "2  000113f07ec002fd  ...          40\n",
              "3  0001b41b1c6bb37e  ...          40\n",
              "4  0001d958c54c6e35  ...          40\n",
              "5  00025465d4725e87  ...          40\n",
              "6  0002bcb3da6cb337  ...          15\n",
              "7  00031b1e95af7921  ...          40\n",
              "8  00037261f536c51d  ...          40\n",
              "9  00040093b2687caa  ...          40\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-ANdICuGrCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Похоже, это все было не нужно, но оставлю на всякий случай. Кластеризация:"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdpqlViY9WRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cluster_metrics(cluster, sample, cluster_num, X, y):\n",
        "  labels = cluster.labels_\n",
        "\n",
        "  print(\"Silhouette Coefficient: %0.3f\"\n",
        "      % metrics.silhouette_score(X[:10000], labels[:10000]))\n",
        "  \n",
        " \n",
        "  print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(y, labels)) \n",
        "  print(\"Completeness: %0.3f\" % metrics.completeness_score(y, labels))\n",
        "  print(\"V-measure: %0.3f\" % metrics.v_measure_score(y, labels)) \n",
        "\n",
        "  print(\"Adjusted Rand Index: %0.3f\"\n",
        "        % metrics.adjusted_rand_score(y, labels))\n",
        "  print(\"Adjusted Mutual Information: %0.3f\"\n",
        "        % metrics.adjusted_mutual_info_score(y, labels))\n",
        "  \n",
        "  sample['cluster'] = cluster.labels_\n",
        "  print(sample[sample.cluster==cluster_num].head(7))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLt2UOQHGJqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "miniX = my_train[:5000]\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C24eweZvGfaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer(max_features=2000, ngram_range=(1,3))\n",
        "X_cv = cv.fit_transform(miniX['comment_text'])\n",
        "svd = TruncatedSVD(50)\n",
        "X_svd = svd.fit_transform(X_cv)\n",
        "y = miniX['cluster']\n",
        "\n",
        "# tfidf = TfidfVectorizer(max_features=500)\n",
        "# X_tf = tfidf.fit_transform(sample1['title'])\n",
        "# y_tf = sample1['category_name']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrDWMv2l_-wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster = AffinityPropagation(damping=0.7, preference=-5, \n",
        "                              max_iter=400, verbose=2)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT0wjmw3GBHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster2 = KMeans(n_clusters=41, max_iter=300, n_init=10)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiRT1RMMGDA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_svd1 = AffinityPropagation(damping=0.7, preference=-5, \n",
        "                              max_iter=400, verbose=2)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyfIUWY2GE2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_svd2 = KMeans(n_clusters=40, max_iter=300, n_init=10)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bme61u4HHDjq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1d6f8960-f6b8-4f0d-ba52-51c8aa7bdd3c"
      },
      "source": [
        "cluster.fit(X_cv)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converged after 137 iterations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AffinityPropagation(affinity='euclidean', convergence_iter=15, copy=True,\n",
              "                    damping=0.7, max_iter=400, preference=-5, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKIEh3trGJnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0af58710-ffaf-4e2c-f63a-0e344ab22b79"
      },
      "source": [
        "cluster2.fit(X_cv)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=41, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Q_CmIAK4Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = cluster.labels_\n",
        "print(set(labels))\n",
        "labels2 = cluster2.labels_\n",
        "print(set(labels2))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFIyezIZMteJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metr(labels, X): \n",
        "  print(\"Silhouette Coefficient: %0.3f\"% metrics.silhouette_score(X[:100], labels[:100]))\n",
        "  print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(y, labels))\n",
        "  print(\"Completeness: %0.3f\" % metrics.completeness_score(y, labels)) \n",
        "  print(\"V-measure: %0.3f\" % metrics.v_measure_score(y, labels)) \n",
        "\n",
        "  print(\"Adjusted Rand Index: %0.3f\"\n",
        "        % metrics.adjusted_rand_score(y, labels))\n",
        "  print(\"Adjusted Mutual Information: %0.3f\"\n",
        "        % metrics.adjusted_mutual_info_score(y, labels))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0UttMweT2nE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "951d0fe3-06f4-4cf1-c5dc-eda6b8cd242d"
      },
      "source": [
        "metr(labels, X_cv)\n",
        "#самое приличное, что вышло(пробовал еще tfidf, и прибавлял разные классификаторы):"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Silhouette Coefficient: 0.020\n",
            "Homogeneity: 0.922\n",
            "Completeness: 0.064\n",
            "V-measure: 0.119\n",
            "Adjusted Rand Index: 0.000\n",
            "Adjusted Mutual Information: -0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNlZQ-lkcgls",
        "colab_type": "text"
      },
      "source": [
        "## **Поиск аутлаеров в данных с помощью кластеризации (нужно найти хотя бы 20 странных не одинаковых текста) **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbcp3L_sox_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster = MeanShift(cluster_all=False, bandwidth=0.5)\n",
        "cluster.fit(X_svd)\n",
        "labels = cluster.labels_"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA6KoDREpku5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b3e2fe76-3804-4edc-df47-7f2c29741cfe"
      },
      "source": [
        "miniX['cluster_num'] = labels"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z0u4XYop1Kw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "96577bfb-9823-415c-f0d5-097ef9a9833c"
      },
      "source": [
        "miniX[miniX.cluster_num==-1]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>008faa76dd3eb890</td>\n",
              "      <td>i only deleted personal attacks</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id                     comment_text  ...    cluster  cluster_num\n",
              "223  008faa76dd3eb890  i only deleted personal attacks  ...  non_toxic           -1\n",
              "\n",
              "[1 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX0owEI_qEdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster = MeanShift(cluster_all=False, bandwidth=0.7,min_bin_freq=0.7)\n",
        "cluster.fit(X_svd)\n",
        "labels = cluster.labels_"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-BMvbJyqRBq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9a7d75ca-3b2e-443e-d27f-41b63d99b8a6"
      },
      "source": [
        "miniX['cluster_num'] = labels"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Y6vNJjO94d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c438254a-78d5-4e65-a43a-2b6d4b7d8fde"
      },
      "source": [
        "len(miniX[miniX.cluster_num==-1])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbT2LZZGqjSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae7ab2e4-7d2f-4ae7-c9fa-e69960cd1c04"
      },
      "source": [
        "#Тут нашлось много странных, они все вообще выглядят странными.\n",
        "miniX[miniX.cluster_num==-1]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>003fa0c68deca750</td>\n",
              "      <td>Check the following websites:\\n\\nhttp://www.iranchamber.com/personalities/farabi/farabi.php\\nhttp://www.islam.org.br/%C2%A0al_farabi.htm\\nhttp://www.superbeyin.com/sohbet/sohbet.htm</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>0097dd5c29bf7a15</td>\n",
              "      <td>u r a tw@ fuck off u gay boy.U r smelly.Fuck ur mum poopie</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic obscene insult identity_hate</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>00e3110f4ff4144f</td>\n",
              "      <td>There I've made him bold. Thats better. Lemmey  talk</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>01e82a7c3b00c42a</td>\n",
              "      <td>Valerie Poxleitner \\n\\nValeri Poxleitner, A.K.A. Lights. If</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>771</th>\n",
              "      <td>020dbbdb2f69bd97</td>\n",
              "      <td>\"Organizations \\n|class=  Start               \\n|importance= Low           \\n|maindykdate=           \\n|needs-infobox= Yes     \\n|needs-image= Yes       \\n|attention=         \\n}}\\n{{WikiProject \"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1131</th>\n",
              "      <td>030f86c7115f78db</td>\n",
              "      <td>thanks \\n\\nthanks but i know</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1341</th>\n",
              "      <td>03a749e7639fd6be</td>\n",
              "      <td>I AM GAY\\nLove\\n  \\nI AM GAY\\nLove\\n  \\nI AM GAY\\nLove</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1418</th>\n",
              "      <td>03d16c4bd7361b6f</td>\n",
              "      <td>Appreciation \\n\\nHi there ACROTERION, from Portugal,\\n\\nplease read</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1531</th>\n",
              "      <td>041e780ba6322faf</td>\n",
              "      <td>Schedule\\nPractice started May 1\\nTime trials May 11, 12, 18, 19\\nRace day May 30\\n\\nhttp://news.google.com/newspapers?id=-20hAAAAIBAJ&amp;sjid;=ZIcFAAAAIBAJ&amp;pg;=5399,2528876&amp;dq;=indianapolis+500&amp;hl;=en</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1648</th>\n",
              "      <td>04740afdec5c0429</td>\n",
              "      <td>God, I just hate them so much. Lets hope they die.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1714</th>\n",
              "      <td>04a694ffe26cbaee</td>\n",
              "      <td>70.146.212.249 \\n\\nOh, don't tell me... (talk)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1755</th>\n",
              "      <td>04c105452355de10</td>\n",
              "      <td>So you can print it out after?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2242</th>\n",
              "      <td>0612e01f974ff6fa</td>\n",
              "      <td>talk:212.121.210.45|talk]]) 11:48, 28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2777</th>\n",
              "      <td>077a020068616b17</td>\n",
              "      <td>Microsoft Jet \\n\\nWhat do you think now? -</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2779</th>\n",
              "      <td>077b1cb88c59f123</td>\n",
              "      <td>no fuckin make me fudge packer 'gwernol'[more like queerhole]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic obscene insult</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2898</th>\n",
              "      <td>07d392354a8fb86e</td>\n",
              "      <td>They NEVER show ads. here...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3043</th>\n",
              "      <td>083864c4df3f7123</td>\n",
              "      <td>BTW: Please reply here. I've watchlisted it. °Talk</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3102</th>\n",
              "      <td>085e6a328ab26ccc</td>\n",
              "      <td>just let me know, and I'll help. Thanks!</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3303</th>\n",
              "      <td>08e737ace8effc43</td>\n",
              "      <td>—Preceding unsigned comment added by  (talk • contribs) 17:01, 3 August 2008\\nFuck off.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3403</th>\n",
              "      <td>092b757bb495e698</td>\n",
              "      <td>\"\\n\\nI didn't edit A2 plane. I edited Reaction Engines A2.  User talk | Contribs \"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3642</th>\n",
              "      <td>09bc1f27b3d79ea3</td>\n",
              "      <td>|importance=\\n|attention=\\n|collaboration-candidate=\\n|past-collaboration=\\n|peer-review= \\n|old-peer-review=\\n\\n|Ancient-Near-East-task-force=\\n|Australian-task-force=\\n|Aviation-task-force=\\n|British-task-force=\\n|Canadian-task-force=\\n|Chinese-task-force=\\n|Classical-task-force=\\n|French-task-force=\\n|Maritime-task-force=yes\\n|Memorials-task-force=\\n|Middle-Ages-task-force=\\n|Napoleonic-task-force=\\n|Polish-task-force=\\n|US-task-force=\\n|Weaponry-task-force=\\n|WWI-task-force=\\n|WWII-task-force=</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3654</th>\n",
              "      <td>09c37b98d3708bd0</td>\n",
              "      <td>BASEBALLS BUGS IS AN UGLY IGNORANT FOOL</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3684</th>\n",
              "      <td>09daddfa2f7d3a8d</td>\n",
              "      <td>Daysleeper STOP Vandalizing FDNY Page</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3713</th>\n",
              "      <td>09eb80efdc787c5b</td>\n",
              "      <td>New comments at bottom, please.\\nComplaints</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4186</th>\n",
              "      <td>0b2a19748d8f9174</td>\n",
              "      <td>What do you mean where did the albums formats disappear?</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4253</th>\n",
              "      <td>0b56f5e4691568e4</td>\n",
              "      <td>FAGGOT \\n FAGGOT \\n FAGGOT \\n FAGGOT</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic obscene insult</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4361</th>\n",
              "      <td>0b98b416a91ddb43</td>\n",
              "      <td>\"\\nBut why does it say \"\"declined\"\"?   \"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4541</th>\n",
              "      <td>0c1290b8f209772f</td>\n",
              "      <td>\"\\nDon't make me laugh.  (talk) \"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4720</th>\n",
              "      <td>0c821e13c9da0baf</td>\n",
              "      <td>Firearms 2 (computer game) deletion question \\n\\nI responded. — talk</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4974</th>\n",
              "      <td>0d28ae577fa7e4e4</td>\n",
              "      <td>please feel free to e mail me</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4979</th>\n",
              "      <td>0d2f51db3bd78bd8</td>\n",
              "      <td>Why do you think I am a troll?  91.55.97.142</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  \\\n",
              "101   003fa0c68deca750   \n",
              "238   0097dd5c29bf7a15   \n",
              "355   00e3110f4ff4144f   \n",
              "702   01e82a7c3b00c42a   \n",
              "771   020dbbdb2f69bd97   \n",
              "1131  030f86c7115f78db   \n",
              "1341  03a749e7639fd6be   \n",
              "1418  03d16c4bd7361b6f   \n",
              "1531  041e780ba6322faf   \n",
              "1648  04740afdec5c0429   \n",
              "1714  04a694ffe26cbaee   \n",
              "1755  04c105452355de10   \n",
              "2242  0612e01f974ff6fa   \n",
              "2777  077a020068616b17   \n",
              "2779  077b1cb88c59f123   \n",
              "2898  07d392354a8fb86e   \n",
              "3043  083864c4df3f7123   \n",
              "3102  085e6a328ab26ccc   \n",
              "3303  08e737ace8effc43   \n",
              "3403  092b757bb495e698   \n",
              "3642  09bc1f27b3d79ea3   \n",
              "3654  09c37b98d3708bd0   \n",
              "3684  09daddfa2f7d3a8d   \n",
              "3713  09eb80efdc787c5b   \n",
              "4186  0b2a19748d8f9174   \n",
              "4253  0b56f5e4691568e4   \n",
              "4361  0b98b416a91ddb43   \n",
              "4541  0c1290b8f209772f   \n",
              "4720  0c821e13c9da0baf   \n",
              "4974  0d28ae577fa7e4e4   \n",
              "4979  0d2f51db3bd78bd8   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                comment_text  \\\n",
              "101   Check the following websites:\\n\\nhttp://www.iranchamber.com/personalities/farabi/farabi.php\\nhttp://www.islam.org.br/%C2%A0al_farabi.htm\\nhttp://www.superbeyin.com/sohbet/sohbet.htm                                                                                                                                                                                                                                                                                                                                    \n",
              "238   u r a tw@ fuck off u gay boy.U r smelly.Fuck ur mum poopie                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "355   There I've made him bold. Thats better. Lemmey  talk                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "702   Valerie Poxleitner \\n\\nValeri Poxleitner, A.K.A. Lights. If                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "771   \"Organizations \\n|class=  Start               \\n|importance= Low           \\n|maindykdate=           \\n|needs-infobox= Yes     \\n|needs-image= Yes       \\n|attention=         \\n}}\\n{{WikiProject \"                                                                                                                                                                                                                                                                                                                     \n",
              "1131  thanks \\n\\nthanks but i know                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
              "1341  I AM GAY\\nLove\\n  \\nI AM GAY\\nLove\\n  \\nI AM GAY\\nLove                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
              "1418  Appreciation \\n\\nHi there ACROTERION, from Portugal,\\n\\nplease read                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
              "1531  Schedule\\nPractice started May 1\\nTime trials May 11, 12, 18, 19\\nRace day May 30\\n\\nhttp://news.google.com/newspapers?id=-20hAAAAIBAJ&sjid;=ZIcFAAAAIBAJ&pg;=5399,2528876&dq;=indianapolis+500&hl;=en                                                                                                                                                                                                                                                                                                                   \n",
              "1648  God, I just hate them so much. Lets hope they die.                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
              "1714  70.146.212.249 \\n\\nOh, don't tell me... (talk)                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "1755  So you can print it out after?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "2242  talk:212.121.210.45|talk]]) 11:48, 28                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "2777  Microsoft Jet \\n\\nWhat do you think now? -                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "2779  no fuckin make me fudge packer 'gwernol'[more like queerhole]                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "2898  They NEVER show ads. here...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
              "3043  BTW: Please reply here. I've watchlisted it. °Talk                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
              "3102  just let me know, and I'll help. Thanks!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "3303  —Preceding unsigned comment added by  (talk • contribs) 17:01, 3 August 2008\\nFuck off.                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "3403  \"\\n\\nI didn't edit A2 plane. I edited Reaction Engines A2.  User talk | Contribs \"                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
              "3642  |importance=\\n|attention=\\n|collaboration-candidate=\\n|past-collaboration=\\n|peer-review= \\n|old-peer-review=\\n\\n|Ancient-Near-East-task-force=\\n|Australian-task-force=\\n|Aviation-task-force=\\n|British-task-force=\\n|Canadian-task-force=\\n|Chinese-task-force=\\n|Classical-task-force=\\n|French-task-force=\\n|Maritime-task-force=yes\\n|Memorials-task-force=\\n|Middle-Ages-task-force=\\n|Napoleonic-task-force=\\n|Polish-task-force=\\n|US-task-force=\\n|Weaponry-task-force=\\n|WWI-task-force=\\n|WWII-task-force=   \n",
              "3654  BASEBALLS BUGS IS AN UGLY IGNORANT FOOL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "3684  Daysleeper STOP Vandalizing FDNY Page                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "3713  New comments at bottom, please.\\nComplaints                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "4186  What do you mean where did the albums formats disappear?                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "4253  FAGGOT \\n FAGGOT \\n FAGGOT \\n FAGGOT                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "4361  \"\\nBut why does it say \"\"declined\"\"?   \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "4541  \"\\nDon't make me laugh.  (talk) \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
              "4720  Firearms 2 (computer game) deletion question \\n\\nI responded. — talk                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "4974  please feel free to e mail me                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
              "4979  Why do you think I am a troll?  91.55.97.142                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
              "\n",
              "      toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
              "101   0      0             0        0       0       0               \n",
              "238   1      0             1        0       1       1               \n",
              "355   0      0             0        0       0       0               \n",
              "702   0      0             0        0       0       0               \n",
              "771   0      0             0        0       0       0               \n",
              "1131  0      0             0        0       0       0               \n",
              "1341  1      0             0        0       0       0               \n",
              "1418  0      0             0        0       0       0               \n",
              "1531  0      0             0        0       0       0               \n",
              "1648  1      0             0        0       0       0               \n",
              "1714  0      0             0        0       0       0               \n",
              "1755  0      0             0        0       0       0               \n",
              "2242  0      0             0        0       0       0               \n",
              "2777  0      0             0        0       0       0               \n",
              "2779  1      0             1        0       1       0               \n",
              "2898  0      0             0        0       0       0               \n",
              "3043  0      0             0        0       0       0               \n",
              "3102  0      0             0        0       0       0               \n",
              "3303  1      0             0        0       0       0               \n",
              "3403  0      0             0        0       0       0               \n",
              "3642  0      0             0        0       0       0               \n",
              "3654  1      0             0        0       0       0               \n",
              "3684  0      0             0        0       0       0               \n",
              "3713  0      0             0        0       0       0               \n",
              "4186  0      0             0        0       0       0               \n",
              "4253  1      0             1        0       1       0               \n",
              "4361  0      0             0        0       0       0               \n",
              "4541  0      0             0        0       0       0               \n",
              "4720  0      0             0        0       0       0               \n",
              "4974  0      0             0        0       0       0               \n",
              "4979  0      0             0        0       0       0               \n",
              "\n",
              "                                 cluster  cluster_num  \n",
              "101   non_toxic                          -1            \n",
              "238   toxic obscene insult identity_hate -1            \n",
              "355   non_toxic                          -1            \n",
              "702   non_toxic                          -1            \n",
              "771   non_toxic                          -1            \n",
              "1131  non_toxic                          -1            \n",
              "1341  toxic                              -1            \n",
              "1418  non_toxic                          -1            \n",
              "1531  non_toxic                          -1            \n",
              "1648  toxic                              -1            \n",
              "1714  non_toxic                          -1            \n",
              "1755  non_toxic                          -1            \n",
              "2242  non_toxic                          -1            \n",
              "2777  non_toxic                          -1            \n",
              "2779  toxic obscene insult               -1            \n",
              "2898  non_toxic                          -1            \n",
              "3043  non_toxic                          -1            \n",
              "3102  non_toxic                          -1            \n",
              "3303  toxic                              -1            \n",
              "3403  non_toxic                          -1            \n",
              "3642  non_toxic                          -1            \n",
              "3654  toxic                              -1            \n",
              "3684  non_toxic                          -1            \n",
              "3713  non_toxic                          -1            \n",
              "4186  non_toxic                          -1            \n",
              "4253  toxic obscene insult               -1            \n",
              "4361  non_toxic                          -1            \n",
              "4541  non_toxic                          -1            \n",
              "4720  non_toxic                          -1            \n",
              "4974  non_toxic                          -1            \n",
              "4979  non_toxic                          -1            "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Cl3WHTSQOU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jri8RBckqllc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "82222f15-b906-4202-d219-81b64c8d9e38"
      },
      "source": [
        "cluster = DBSCAN(min_samples=5.1, eps=35.7, leaf_size=70,  ) \n",
        "cluster.fit(X_svd)\n",
        "labels = cluster.labels_\n",
        "miniX['cluster_num'] = cluster.labels_"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiO5OX-DMt9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40047242-0f40-44f1-f5b7-aa109011e1ed"
      },
      "source": [
        "print(len(miniX[miniX.cluster_num==-1]))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzFFSxFcrx_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1d29e40-f5d4-4ea2-fdf3-88cfef5ac230"
      },
      "source": [
        "#Ну вот здесь большинство странные, за редким исключением:\n",
        "miniX[miniX.cluster_num==-1]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>0218713b96c82905</td>\n",
              "      <td>Other Bush articles not referenced in George W. Bush\\nNone of the following articles is mentioned in the George W. Bush and perhaps should be:\\n Bush's Brain: How Karl Rove Made George W. Bush Presidential\\n Domestic policy of the George W. Bush administration\\n Early life of George W. Bush\\n Economic policy of the George W. Bush administration\\n Electoral history of George W. Bush\\n Fictionalized portrayals of George W. Bush\\n Foreign policy of the George W. Bush administration\\n George W. Bush and the Iraq War\\n George W. Bush as Governor of Texas\\n George W. Bush Cabinet\\n George W. Bush presidential campaign\\n George W. Bush presidential campaign, 2000\\n George W. Bush Presidential Library\\n George W. Bush pretzel incident\\n George W. Bush substance abuse controversy\\n George W. Bush Supreme Court candidates\\n George W. Bush's first term as President of the United States\\n George W. Bush's second term as President of the United States\\n List of books and films about George W. Bush\\n List of George W. Bush legislation and programs\\n List of nicknames used by George W. Bush\\n List of people pardoned by George W. Bush\\n Mahmoud Ahmadinejad's letter to George W. Bush\\n Movement to impeach George W. Bush\\n Presidency of George W. Bush\\n Professional life of George W. Bush\\n Public perception of George W. Bush\\n Religious faith of George W. Bush\\n The Lies of George W. Bush: Mastering the Politics of Deception</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1043</th>\n",
              "      <td>02d9ff88fc2893c8</td>\n",
              "      <td>\"\\n\\nOrphaned non-free image (Image:KSV Hessen Kassel.png)\\n Thanks for uploading Image:KSV Hessen Kassel.png. The image description page currently specifies that the image is non-free and may only be used on Wikipedia under a claim of fair use. However, the image is currently orphaned, meaning that it is not used in any articles on Wikipedia. If the image was previously in an article, please go to the article and see why it was removed. You may add it back if you think that that will be useful. However, please note that images for which a replacement could be created are not acceptable for use on Wikipedia (see our policy for non-free media).\\n\\nIf you have uploaded other unlicensed media, please check whether they're used in any articles or not. You can find a list of 'image' pages you have edited by clicking on the \"\"my contributions\"\" link (it is located at the very top of any Wikipedia page when you are logged in), and then selecting \"\"Image\"\" from the dropdown box. Note that any non-free images not used in any articles will be deleted after seven days, as described on criteria for speedy deletion. Thank you.  \\nOrphaned non-free image (Image:Darmstadt98.png)\\n Thanks for uploading Image:Darmstadt98.png. The image description page currently specifies that the image is non-free and may only be used on Wikipedia under a claim of fair use. However, the image is currently orphaned, meaning that it is not used in any articles on Wikipedia. If the image was previously in an article, please go to the article and see why it was removed. You may add it back if you think that that will be useful. However, please note that images for which a replacement could be created are not acceptable for use on Wikipedia (see our policy for non-free media).\\n\\nIf you have uploaded other unlicensed media, please check whether they're used in any articles or not. You can find a list of 'image' pages you have edited by clicking on the \"\"my contributions\"\" link (it is located at the very top of any Wikipedia page when you are logged in), and then selecting \"\"Image\"\" from the dropdown box. Note that any non-free images not used in any articles will be deleted after seven days, as described on criteria for speedy deletion. Thank you.  \\nOrphaned non-free image (Image:Eintrachtbraunschweig.png)\\n Thanks for uploading Image:Eintrachtbraunschweig.png. The image description page currently specifies that the image is non-free and may only be used on Wikipedia under a claim of fair use. However, the image is currently orphaned, meaning that it is not used in any articles on Wikipedia. If the image was previously in an article, please go to the article and see why it was removed. You may add it back if you think that that will be useful. However, please note that images for which a replacement could be created are not acceptable for use on Wikipedia (see our policy for non-free media).\\n\\nIf you have uploaded other unlicensed media, please check whether they're used in any articles or not. You can find a list of 'image' pages you have edited by clicking on the \"\"my contributions\"\" link (it is located at the very top of any Wikipedia page when you are logged in), and then selecting \"\"Image\"\" from the dropdown box. Note that any non-free images not used in any articles will be deleted after seven days, as described on criteria for speedy deletion. Thank you.  \\nOrphaned non-free image (Image:Karlsruher SC.png)\\n Thanks for uploading Image:Karlsruher SC.png. The image description page currently specifies that the image is non-free and may only be used on Wikipedia under a claim of fair use. However, the image is currently orphaned, meaning that it is not used in any articles on Wikipedia. If the image was previously in an article, please go to the article and see why it was removed. [[WP:BOLD|You m</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308</th>\n",
              "      <td>0392452585b760e3</td>\n",
              "      <td>\"\\nWrong licenses\\nI have corrected the licenses for the majority of the images you have uploaded. The exceptions are:\\n:Image:Wankhede Mumbai.jpg - On the flickr page the author has apparently agreed to license the image under one of the free Creative Commons licenses, but failed to actually change the licensing. \\n:Image:Dhoom2.jpg - Concern that the creator is in no position to submit the image under a Creative Commons license, as it depicts a billboard for a film and copyright to it is held by somebody else than the photographer. As such, the photo may not be used on Wikipedia, except perhaps under fair use policy (which probably doesn't apply), or under panorama freedom (depending on what the copyright law of India says on this topic).\\n:Image:Bipasha.jpg - Image description page implies that it is licensed for non-commercial use only (contradicting your copyright tag); such a restriction is not acceptable on Wikipedia. In addition, the link to the original source (which could clarify which condition is correct) of the image is missing.\\n:Image:Bom.jpg - The link to the original source at flickr is missing; author uploads images to flickr as \"\"all rights reserved\"\". \\n:Image:Chowpatti.jpg - To verify that the image is indeed under the license you claim, the author should probably e-mail the Wikimedia Foundation and confirm that it is indeed under that license.\\n:Image:Hydmall.jpg - The flickr page states that it is under a Creative Commons No-Derivative license; a license that prohibits the image to be modified/used in derivative works is not acceptable on Wikipedia, either.\\n:Image:Infobangalore.jpg - No evidence of the image being under a free license.\\n:Image:Brigaderoad.jpg - Flickr page states \"\"all rights reserved\"\".\\n:Image:Hoogly.jpg - The link to the original source at flickr is missing; author uploads images to flickr as \"\"all rights reserved\"\".\\n:Image:Haf.jpg - Flickr page states \"\"all rights reserved\"\".\\n:Image:Bangtemp.jpg - Creative Commons No-Derivative license.\\n:Image:Kolkahomes.jpg - All rights reserved.\\n:Image:Delhimall.jpg - Creative Commons Attribution Non-commercial No-derivative license (unacceptable on Wikipedia).\\n:Image:Yamun.jpg - All rights reserved.\\n:Image:Kolk.jpg - All rights reserved.\\n:Image:Myspalbang.jpg - All rights reserved.\\n:Image:Bangalore.jpg - The link to the original source is missing; no evidence that it is under the Creative Commons license.\\n:Image:Lalbagh.jpg - Taken from WikiTravel. Uploader ought to confirm that he is indeed under the author and that he has licensed it under the license indicated.\\n:Image:Nagpur.JPG - Who made this image?\\n\\nThere are several issues here. There are multiple Creative Commons licenses, not all of which are acceptable on Wikipedia. In particular, licenses that prohibit commercial use or making of derivative works are considered unfree and can't be used on Wikipedia, except as provided by the fair use policy; Creative Commons Atrribution, and Creative Commons Atrribution Sharealike licenses are okay. Also, there are multiple versions of the licenses; Creative Commons Atrribution Sharealike 1.0, 2.0, 2.5, and 3.0 are all distinct licenses. (The problem is that the upload dialogue only lists the 3.0 versions and not the earlier ones; when the image is under one of the older licenses, you ought to edit the image description page and correct the number. As far as I can see, Flickr only uses the 2.0 versions of the licenses.)\\n\\nIn addition, some of the Flickr authors have indicated that they allow the image to be used on Wikipedia, without making it clear that they release it under one of the acceptable licenses; a permission that only extends to Wikipedia is not sufficient, either. You should ask the authors to do one of the following:\\nChange the Flickr page to license the image under Creative Commons Attribution (or Attribution Sharealike) license (apparently, this would change the licensing for all images, and this may not be what they intend to do);\\nPost a message to the image page with a text similar to the following:\\nI, creator of the image, agree to license it under the Creative Commons Attribution license (link) [alternately: under the Creative Commons Attribution Sharealike license (link). This declaration overrides any statement to the contrary on this page.\\nE-mail the Wikimedia Foundation (permissions-en[AT]wikimedia[DOT]org) with a message similar to the above, also specifying which image (images) the user intends to release under the license. (This would be the best choice if the author doesn't want to reveal his identity on Wikip</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>06168775082a96d2</td>\n",
              "      <td>YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER!</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic sever_toxic obscene insult</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2349</th>\n",
              "      <td>064b57734ce5aad0</td>\n",
              "      <td>India Magical Trip, is one of the few tour operators in India, who offer an extraordinary touring experience to countless tourists throughout the year. Their experienced tour operators knows exactly what their clients are looking for and they design, innovate tour packages which their clients have very impressed with. What makes India Magical Trip so special is the fact that they arrange for most innovative and attractive tour packages, at a very reasonable rate. \\n\\nTheir tour packages take care of all the ins and outs of their guests in terms of accommodation, travelling, food. To sum it up, India Magical Trip offers an incredible touring experience to its clients.  \\n \\nAbout the Company\\n\\nIndia Magical Trip is an online tour operator who started serving their global tourists from the year 2014. Though new in this field, they have garnered enough reputation in only one year due to their top-notch services and offerings. They have a wide array of different types of packages to offer to their valuable clients. Besides, their skilled tour planners can arrange for customized India tours according to the preferences of their clients. All their clients need to do is to visit their official website, fill in the enquiry form and they would present a free quote to the clients as per the customized packages. \\n\\nIndia Magical Trip is dedicated to take the concept of touring to a new level altogether. They are certainly one of the most reliable names in the tourism fraternity in India.\\n\\nAbout the Founders\\n\\nIndia Magical Trip was founded by two enthusiastic individuals, Mr. Prem Dhiman, Director of Sales, and Mr. Sumit Dahiya, Director of IT, with a vision to put up an online setup which would offer extraordinary touring experience, where people all across the globe would get to know India with its real beauty and true colors. India Magical Trip being their dream child has been carefully nurtured and given the shape and status that it is having today.\\n\\nPackages Offered\\n\\nIndia Magical Trip is known for designing some of the most innovative and customized tour packages for its clients. Besides, they have some pre-set tour packages which covers a wide range of Indian tourism. \\n\\n1. Golden Triangle Tour  This is one of their most demanded tour packages. In this package, their guests are exposed to the beauty, charm and grace of northern India. This tour covers some of the most famous tourist destinations in India, which includes majestic Agra, country capital Delhi and city of palaces, Jaipur. \\n\\n2. Rajasthan Tour 'Bold text The most reliable and convenient way to enjoy the heritage and beauty of Rajasthan is through India Magical Trip. Their Rajasthan Tour package would present the true color of the Rajasthani culture, which include, trip to some of the famous forts in India, enjoying wonderful lakes, desert safari, tour to wildlife reserves and many more. \\n\\n3. North India Tour  The North India Tour arranged by India Magical Trip covers some of the most attractive and famous tourist destinations in this part of the country. It includes visits to some of the most wonderful hill stations in the country, monuments, pilgrimage centres and several others. \\n\\n4. Kerala tour   Kerala is one of the most beautiful places located in South India. India Magical Trip has some of the most excellent facilities and arrangements for their clients where they are exposed to the natural beauty of this land. This tour is all about discovering the vast culture, hill stations, wildlife and others. \\n\\n5. Yoga and Ayurvedic  India Magical Trip has some of the most enchanting and refreshing packages for their clients. Yoga and Ayurveda have been a part of India tradition and this tour would expose their guests to experience the ancient India therapies in the form of Ayurveda and to work out in the form of Yoga.\\n\\n6. Adventure and Wildlife tour ' India as a country which is full of wildlife and dense forests the magical India trip will arrange for its clients to experience some of the most exciting and adventurous wildlife tours.\\n\\nWith a goal to reach out to more and more global travel lovers, India Magical Trip is striving hard by employing as much resources as possible. Very shortly they are going to come up with a more organized setup to serve their elite guests in a better way.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2366</th>\n",
              "      <td>065b10e83e654132</td>\n",
              "      <td>User:NHRHS2010 is a homo like mitt romney is. \\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.\\n User:NHRHS2010 is a homo like mitt romney is. \\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. NEWL</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic obscene insult identity_hate</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2420</th>\n",
              "      <td>067c5e814e88a56b</td>\n",
              "      <td>FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic sever_toxic obscene insult</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2567</th>\n",
              "      <td>06e08f9a9acb421a</td>\n",
              "      <td>Towns and Villages in Ark-La-Tex]]\\n Cities, boroughs and towns in the Republic of Ireland\\n Cities, boroughs, and townships along the Susquehanna River\\n Cities, towns and villages in Alborz Province\\n Cities, towns and villages in Ardabil Province\\n Cities, towns and villages in Bhutan\\n Cities, towns and villages in Bushehr Province\\n Cities, towns and villages in Chaharmahal and Bakhtiari Province\\n Cities, towns and villages in Cyprus\\n Cities, towns and villages in Dutch Limburg\\n Cities, towns and villages in East Azerbaijan Province\\n Cities, towns and villages in East Timor\\n Cities, towns and villages in Fars Province\\n Cities, towns and villages in Flevoland\\n Cities, towns and villages in Friesland\\n Cities, towns and villages in Gelderland\\n Cities, towns and villages in Gilan Province\\n Cities, towns and villages in Golestan Province\\n Cities, towns and villages in Groningen\\n Cities, towns and villages in Hamadan Province\\n Cities, towns and villages in Hormozgan Province\\n Cities, towns and villages in Ilam Province\\n Cities, towns and villages in Isfahan Province\\n Cities, towns and villages in Kerman Province\\n Cities, towns and villages in Kermanshah Province\\n Cities, towns and villages in Khuzestan Province\\n Cities, towns and villages in Kohgiluyeh and Boyer-Ahmad Province\\n Cities, towns and villages in Kurdistan Province\\n Cities, towns and villages in Lorestan Province\\n Cities, towns and villages in Markazi Province\\n Cities, towns and villages in Mazandaran Province\\n Cities, towns and villages in North Brabant\\n Cities, towns and villages in North Holland\\n Cities, towns and villages in North Khorasan Province\\n Cities, towns and villages in Overijssel\\n Cities, towns and villages in Qazvin Province\\n Cities, towns and villages in Qom Province\\n Cities, towns and villages in Razavi Khorasan Province\\n Cities, towns and villages in Saint Vincent and the Grenadines\\n Cities, towns and villages in Samoa\\n Cities, towns and villages in Semnan Province\\n Cities, towns and villages in Sistan and Baluchestan Province\\n Cities, towns and villages in South Holland\\n Cities, towns and villages in South Khorasan Province\\n Cities, towns and villages in Tehran Province\\n Cities, towns and villages in Turkmenistan\\n Cities, towns and villages in Utrecht\\n Cities, towns and villages in Vojvodina\\n Cities, towns and villages in West Azerbaijan Province\\n Cities, towns and villages in Yazd Province\\n Cities, towns and villages in Zanjan Province\\n Cities, towns and villages in Zeeland\\n Cities, towns and villages in the Maldives\\n Cities, towns and villages in the Solomon Islands\\n Cities, towns, and villages in Békés county\\n Cities, towns, and villages in Louisiana</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2799</th>\n",
              "      <td>078a7beb1a1be141</td>\n",
              "      <td>\"\\n\\nBELOW IS THE ZAFARNAMAH (a religious letter of victory) by GURU GOBIND SINGH JI\\nOut of 111 verses \\n\\n1)34 verses are in the praise of AKAL PURAKH WAHEGURU \\n\\n2)32 verses deals with Aurangzeb 's invitation for the Guru to meet him and the Guru's refusal to meet Aurangzeb - instead the Guru asks him (Aurangzeb) to visit him.\\n\\n3)24 verses deals with the detail events that took place during the BATTLE OF CHAMKAUR (December,1704)\\n\\n4)15 verses reprove Aurangzeb for breaking promises given by him and his agents (Nawab Wazir Khan, Raja Ajmer chand and other hilly rajas)\\n\\n5)6 verses deals with the praise of Aurangzeb.\\n\\nIn the verse 78 and 79 Guru Gobind singh also had warned Aurangzeb that KHALSA will not rest until the evil empire is destroyed.\\n\\n'''''''''ZAFARNAMAH (a religious letter of victory) written by GURU GOBIND SINGH to MUGHAL EMPEROR AURANGZEB.\\n1)The Lord is perfection personified.He is eternal and manifests himself through his miracles.He is generous in granting his bounties.He is merciful and delivers us from the world.\\n2)He grants peace and security and is always merciful in forgiving us for our sins.He holds our hand and guides us.He is provider of our sustenance and charms everyone.\\n3)Lord is the king of kings who is guiding us all the time.He showers his benevolence on all.He is without colour, incomparable and formless.\\n4)He possesses no material things nor has he an army.He is merciful and grants all the pleasures of the heavens.\\n5)The pure one is above everything in this universe.His glory is all pervasive.He bestows us with gifts.He is present everywhere.\\n6)The merciful Lord grants us all the gifts and meets the needs of everyone throughout the world.\\n7)He is Lord of the universe.He is merciful and provides sustenance to all.His charm andd grandeur cannot be matched by anyone.\\n8)The Lord is intelligence personified.He protects the poor and the helpless and destroys the wicked.\\n9)The virtuous one gives justice to all.Nothing is hidden from him.He is the inspiration of Quran.\\n10)The all-knowing Lord seeks the learned.He is aware of all happenings.He is present everywhere.\\n11)He has the knowledge of everything in this universe.All cosmos is moving as per his command.\\n12)The great Lord is regulating everything in the world about which he has complete knowledge.\\n13)Aurangzeb ! I have no trust in your oaths anymore. (you have written that) God is one and that he is witness (between us).\\n14)I don't have trust even equivalent to a drop of water in your generals (Wazir Khan, nawab of Sirhind Punjab, Raja Ajmer chand (rajput hilly king) and other hilly kings who came to me with oaths of Quran and cow that I will be given safe passage out of Anandgarh fort. But they all were telling lies\\n15) If anyone trusts you on your oaths of Quran that person is bound to be doomed in the end.\\n16)If anyone comes under the shadow of Huma bird, no one can lay its hands on it-not even a brave cow.\\n17)If a man sits behind the back of a lion neither anyone can catch him nor a goat or a sheep or a deer can even pass nearby.\\n(Aurangzeb ! I stand in shadow of the Almighty and your men who are like goats,sheep and deer could not harm me inspite of your deceptions.)\\n18)If I had deceived by taking oath on Holy Quran like the way you have done, I would not have bought my dear fighters to this position of disadvantage (by bringing them out of Anandgarh fort).\\nIN VERSES FROM 19 TO 41 BELOW, GURU SAHIB GAVE AN ACCOUNT OF THE BATTLE OF CHAMKAUR FOUGHT ON 22ND DECEMBER,1704 AND THE REASONS THAT FORCED HIM TO TAKE UP THE SWORD AGAINST THE MUGHALS AND HILLY RAJPUT KINGS\\n19)what can 40 hungry men do when suddenly 10 lakh (one million) strong army pounces upon them ?\\n20)That the promise breakers launched a surprise attack with their swords, arrows and guns.\\n21)It was out of sheer helplessness that I came in the battle field.(Having thus decided) I came with all the battle plans and munitions.\\n22)When all stratagem employed for (solving) a problem are exhausted, only then taking your hand to the sword is legitimate.\\n(This is the most quoted of Zafarnamah.300 years ago, Guru Gobind singh ji had laid down the circumstances when a person or a nation can pick up the sword against the other)\\n23)What trust can I have on your oath on Quran ? Otherwise you tell why should I have taken path of taking up the sword.\\n24)I do not know that this person (Aurangzeb) is cunning like a fox.Otherwise I would never have come to this place that is Chamkaur (by vacating Anandgarh on the false oaths of Aurangzeb and his men).\\n25)If any person believes an oath on Quran ,he should neither be tied (arrested) nor killed.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2920</th>\n",
              "      <td>07e36fc910bd3eec</td>\n",
              "      <td>\"Contents of the library (objects and functions to be used outside, situation\\nlate August 2004)\\n\\nClasses:\\nPage: A MediaWiki page\\n    __init__               Page(Site, Title) - the page with title Title on wikimedia site Site\\n    title                  The name of the page, in a form suitable for an interwiki link\\n    urlname                The name of the page, in a form suitable for a URL\\n    titleWithoutNamespace  The name of the page, with the namespace part removed\\n    section                The section of the page (the part of the name after '#')\\n    sectionFreeTitle       The name without the section part\\n    aslink                 The name of the page in the form Title or lang:Title\\n    site                   The wiki this page is in\\n    encoding               The encoding of the page\\n    isAutoTitle            If the title is a well known, auto-translatable title\\n    autoFormat             Returns (dictName, value), where value can be a year, date, etc.,\\n                            and dictName is 'YearBC', 'December', etc.\\n    isCategory             True if the page is a category, false otherwise\\n    isImage                True if the page is an image, false otherwise\\n\\n    get (*)                The text of the page\\n    exists (*)             True if the page actually exists, false otherwise\\n    isRedirectPage (*)     True if the page is a redirect, false otherwise\\n    isEmpty (*)            True if the page has 4 characters or less content, not\\n                            counting interwiki and category links\\n    botMayEdit (*)         True if bot is allowed to edit page\\n    interwiki (*)          The interwiki links from the page (list of Pages)\\n    categories (*)         The categories the page is in (list of Pages)\\n    linkedPages (*)        The normal pages linked from the page (list of Pages)\\n    imagelinks (*)         The pictures on the page (list of ImagePages)\\n    templates (*)          All templates referenced on the page (list of strings)\\n    getRedirectTarget (*)  The page the page redirects to\\n    isDisambig (*)         True if the page is a disambiguation page\\n    getReferences          List of pages linking to the page\\n    namespace              The namespace in which the page is\\n    permalink (*)          The url of the permalink of the current version\\n    move                   Move the page to another title\\n    put(newtext)           Saves the page\\n    put_async(newtext)     Queues the page to be saved asynchronously\\n    delete                 Deletes the page (requires being logged in)\\n\\n    (*)  This loads the page if it has not been loaded before; permalink might\\n          even reload it if it has been loaded before\\n\\nSite: a MediaWiki site\\n    messages               There are new messages on the site\\n    forceLogin()           Does not continue until the user has logged in to\\n                            the site\\n    getUrl()               Retrieve an URL from the site\\n    mediawiki_message(key): Retrieve the text of the MediaWiki message with\\n                            the key \"\"key\"\"\\n    has_mediawiki_message(key)  True if this site defines a MediaWiki message\\n                                 with the key \"\"key\"\"\\n    Special pages:\\n        Dynamic pages:\\n            allpages(): Special:Allpages\\n            newpages(): Special:Newpages\\n            longpages(): Special:Longpages\\n            shortpages(): Special:Shortpages\\n            categories(): Special:Categories\\n\\n        Cached pages:\\n            deadendpages(): Special:Deadendpages\\n            ancientpages(): Special:Ancientpages\\n            lonelypages(): Special:Lonelypages\\n            uncategorizedcategories(): Special:Uncategorizedcategories\\n            uncategorizedpages(): Special:Uncategorizedpages\\n            unusedcategories(): Special:Unusuedcategories\\n\\nOther functions:\\ngetall(): Load pages via Special:Export\\nsetAction(text): Use 'text' instead of \"\"Wikipedia python library\"\" in\\n    editsummaries\\nhandleArgs(): Checks whether text is an argument defined on wikipedia.py\\n    (these are -family, -lang, -log and others)\\ntranslate(xx, dict): dict is a dictionary, giving text depending on language,\\n    xx is a language. Returns the text in the most applicable language for\\n    the xx: wiki\\nsetUserAgent(text): Sets the string being passed to the HTTP server as\\n    the User-agent: header. Defaults to 'Pywikipediabot/1.0'.\\n\\noutput(text): Prints the text 'text' in the encoding of the user's console.NEWL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3090</th>\n",
              "      <td>0856c9ea94df1446</td>\n",
              "      <td>FK Vardar \\n\\nFK Vardar is a Macedonian Football club, the club changed its name several times during its history, from original Vardar in 1911 to Citizens Football Club Vardar or just Citizens( Gragjanski in Macedonian ) in 1920, then Football Club Makedonija in 1946 and finally back to FC Vardar in 1947. By the name FC Citizens( Vardar ) the club won 4 championships from 1936 till 1939. About Yugoslavia, you have to know that Yugoslavia was a federation of 6 Republics -countries together and each Republic had its own championship, and there was a Federal League where teams from the Republics competed together. Each Republic had its own Cup and the cup winners competed in the Marshals Cup, that cup was held in honor of Joseph Broz the marshal of the Federation, and its was called the Cup of the Marshal. How ever FC Vardar never won the Federal league ( League made of Federation of 6 Republics best teams ,thats why its called the Federal League, and not Yugoslavian League nor Yugoslavian Cup). The title in 1987 was won by FC Partizan Belgrade , you can check in any official statistics or documents. The second federal league was made of two Second Federal Leagues , East ( 3 Republics competed, Serbia ,Monte Negro,Macedonia and two Provinces- almost the same as Republics but yet without a nation ,those were Kosovo and Vojvodinship ) and West ( 3 Republics, Croatia, Bosnia and Slovenia, sometimes clubs from province Vojvodinship  would compete in the West depending on the federation decisions ). In the period of 1922 till 1929, present day Republic of Macedonia was established as 4 provinces within the Kingdom of Serbs Croats and Slovenes, those 4 provinces were Skopje, Bitola,Shtip and Vranje prvinces. These 4 provinces established the Macedonian Football Federation in 1926,and they held 3 championships. In 1929 these 4 provinces joined in one Duchy and this championship was held in the Duchy ( Banovina ) for 11 times.During the WW2 the championship was held under German Occupation, and the German government recognized this League. After the WW2 the very same championship was tranformed in to Republic Football League ,just the Province of Vranje was separated from the Republic as Macedonia transformed from Duchy to a Republic and the province of Vranje was under the newly made Republic of Serbia in 1946. The bottom line is since the Federation of 6 Republics split in the 90s, Macedonian Republic League was transformed in to Macedonian First League. So it is the same League that changed names and competition format during the decades, and now it came to this Level. Its a petty that there is lots of politics and territorial pretensions lots of denial of the existence of the Macedonia and other Republics in the Federation , by the Serbian side. Serbian official politic is to show that Yugoslavia was one country and nation mainly based on Serb character and they are stilling all the history including history of sports in this case football. They are trying to show the world that there was Yugoslav nation ( Serb ) and only Yugoslav Football league ( Serb League ) denying the Federal League second Federal League and Republic Leagues. They want to show only Yugoslav League and not the real Federal League. They hold all the champions from the Federal League as Serbian Champions in every competition. For FC Vardar at this point of view considering that  Macedonia is not in the Federetion for more than 20 years,and it wont be in the future ,the most important are the titles and trophies won in the Macedonian League , and if you wont to put additional trophies won in the Federation ,the period before 1991 you should write the precise information. Second Federal League East is the name of the competition, and you should put the Macedonian Flag from that period of the time next to it,instead of the federal flag, simply because that federation dont exist anymore and doesnt represent any country nor nation. About the cup , you should write down the real proper name as it was called ,Marshals Cup also fallowed by Macedonian flag from that period of the time, you should put a notice that in the Federal Second League East , clubs from Serbia Macedonia and Monte Negro competed including the provinces of Kosovo i Vojvodinship.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3352</th>\n",
              "      <td>090a0d1ebb5d71b8</td>\n",
              "      <td>\"\\n\\n The Truth about the 1986 Sinn Féin Ard Fheis \\n\\nThe story of how Gerry Adams tried to turn an eighty year old revolutionary movement into a British Constitutional party.  How he broke the Sinn Féin constitution, created fake cumainn to give him fake votes and barred life long republicans from voting.  How he managed to expel himself and his supporters from Sinn Féin membership.  And, how a small band of republicans managed to keep the Sinn Féin constitution and traditional policy in tact. \\n\\nIn 1986 Section 1b. of the Sinn Féin constitution read as follows:\\n\\n“No person who is a member of any political party organisation or who approves of or supports the candidature of persons who, if elected, intend taking part in the proceedings of the Westminster or partitionist 26-County or 6-County  parliaments or who approves of or supports the candidature of persons who sign any form or give any kind of written or verbal undertaking of intention to take their seats in these institutions, shall be admitted to membership or allowed to retain membership.\"\" \\n\\nThe Adams leadership put forward a motion, titled Resolution 162, at the 1986 Ard Fheis.  Its wording was as follows: \\n\\nRESOLUTION 162\\n\\nTHAT this Ard-Fheis drops its abstentionist attitude to Leinster House. Successful Sinn Fein parliamentary candidates in 26-County elections:\\n\\na. Shall attend Leinster House as directed by the Ard Chomhairle.\\n\\nb. Shall not draw their salaries for personal use. (Parliamentary representatives shall be paid a Sinn Fein organiser’s subsidy, and the Leinster House salary shall be divided at the direction of the Ard Chomhairle to defray national and constituency expenses.)\\n\\nTo accommodate this change, the Constitution and Rules be amended as follows:\\n\\nThat Section 1b of the Constitution be amended to read:\\n \\nNo person who is a member of any political party organisation or who approves of or supports the candidature of persons who, if elected, intend taking part in the proceedings of the Westminster or partitionist 6-County parliaments or who approves of or supports the candidature of persons who sign any form or give any kind of written or verbal undertaking of intention to take their seats in these institutions, shall be admitted to membership or allowed to retain membership. \\n\\nMotion 162 supports and approves of the candidature of persons who, if  elected, would be of the intention to take their seats in certain circumstances i.e. on the direction of the Ard Chomhairle.  Obviously, Motion 162 infringes Section 1b.  Section 1b. was in effect at the time this Resolution was presented.  Its clear that Adams made a mistake in procedure.  He should have sought a majority decision to amend Section 1b. in 1986 and returned in 1987 to propose entering Leinster House.  Trying to amend Section 1b. and propose taking seats in the “partitionist 26-County Parliament” in the same Resolution was a logical impossibility. \\n\\nCan anybody say that  the wording:\\n\\n“That this Ard-Fheis drops its abstentionist attitude to Leinster House. Successful Sinn Fein parliamentary candidates in 26-County elections:\\n\\na.  Shall attend Leinster House as directed by the Ard Chomhairle”\\n\\ndoes not constitute the supporting and approving of the candidature of persons who intend to take their seats in Leinster House as directed by the Ard Chomhairle?\\nClearly Adams was in breach of Section 1b. and according to that section he had expelled himself, and all those who voted for Resolution 162.\\n\\nBrian Feeney, in his book, Sinn Féin 100 Turbulent Years, puts forward the argument that Adams had managed to bypass Section 1b, by introducing a motion in 1983 allowing the “discussion” of any aspect of the Sinn Féin constitution.  This change may indeed have facilitated debate on abstentionism but it did not infringe on the content or effect of Section 1b in any way.  To discuss something is not the same as formally proposing or supporting it.  For example, conventions are held regularly where drug addiction is discussed without any of the delegates proposing or supporting it.  In fact the line Adams added in 1983 was superfluous, as the Sinn Féin constitution had never banned the “discussion” of anything – just the “approving” and “supporting” of taking seats in named partitionist parliaments.\\n\\nOf course its not illegal to amend or remove section 1b. Section 1b. bans the approval or support of candidates who intend to take seats in British assemblies. It can be removed or amended at any Ard Fheis by a two thirds majority. The reason for doing so could be many. Perhaps delegates might feel that it implies that they cannot be trusted to be loyal to the Republic. In fact its not necessary, according to the constitution, to give any reason. But you</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>0b2055f13934a41e</td>\n",
              "      <td>ii CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND AR</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic obscene insult</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4557</th>\n",
              "      <td>0c1c007ab2d6d30f</td>\n",
              "      <td>\"\\nTABTABTAB             ==Criminal Life ==\\nViolenciafriki is a Homosexual petifile with 135.78 counts of rape all of which were men and children, served a sentence of 23 years before being deported back to Spain, from there he hooked up with the user Slimvirgin and together killed 1034 people with bomb.  Violenciafriki is now a key person in the Al-quida terrorism group.  In the past 10 years he has made a total 7,998 calls to Michael Jackson.\\n\\nTABTABTAB         ==His Happy Rape Secrets==\\n\\nHe says \"\"I will Never stop under any cirumstances. I Love it Hahaha\"\"\\n\\nThere is substantial proof connecting Violenciafriki (asswipe) to 9/11 and we think that he is a second cousin to Osama Bin-Ladin.  Osama has his own happy rape secrets as well.\\n\\nHe describes 9/11 as the \"\"best thing that has ever happened, i repeat EVER,\"\" then mumbled off talking about raping a boy named Jimmy Brown in Columbia,SC (Jimmy Brown is a 15 year kid convicted of rape of is 4 year old brother and molestation of a 14 year old girl.\\nTABTABTAB             ==Criminal Life ==\\nViolenciafriki is a Homosexual petifile with 135.78 counts of rape all of which were men and children, served a sentence of 23 years before being deported back to Spain, from there he hooked up with the user Slimvirgin and together killed 1034 people with bomb.  Violenciafriki is now a key person in the Al-quida terrorism group.  In the past 10 years he has made a total 7,998 calls to Michael Jackson.\\n\\nTABTABTAB         ==His Happy Rape Secrets==\\n\\nHe says \"\"I will Never stop under any cirumstances. I Love it Hahaha\"\"\\n\\nThere is substantial proof connecting Violenciafriki (asswipe) to 9/11 and we think that he is a second cousin to Osama Bin-Ladin.  Osama has his own happy rape secrets as well.\\n\\nHe describes 9/11 as the \"\"best thing that has ever happened, i repeat EVER,\"\" then mumbled off talking about raping a boy named Jimmy Brown in Columbia,SC (Jimmy Brown is a 15 year kid convicted of rape of is 4 year old brother and molestation of a 14 year old girl.\\nTABTABTAB             ==Criminal Life ==\\nViolenciafriki is a Homosexual petifile with 135.78 counts of rape all of which were men and children, served a sentence of 23 years before being deported back to Spain, from there he hooked up with the user Slimvirgin and together killed 1034 people with bomb.  Violenciafriki is now a key person in the Al-quida terrorism group.  In the past 10 years he has made a total 7,998 calls to Michael Jackson.\\n\\nTABTABTAB         ==His Happy Rape Secrets==\\n\\nHe says \"\"I will Never stop under any cirumstances. I Love it Hahaha\"\"\\n\\nThere is substantial proof connecting Violenciafriki (asswipe) to 9/11 and we think that he is a second cousin to Osama Bin-Ladin.  Osama has his own happy rape secrets as well.\\n\\nHe describes 9/11 as the \"\"best thing that has ever happened, i repeat EVER,\"\" then mumbled off talking about raping a boy named Jimmy Brown in Columbia,SC (Jimmy Brown is a 15 year kid convicted of rape of is 4 year old brother and molestation of a 14 year old girl.\\nTABTABTAB             ==Criminal Life ==\\nViolenciafriki is a Homosexual petifile with 135.78 counts of rape all of which were men and children, served a sentence of 23 years before being deported back to Spain, from there he hooked up with the user Slimvirgin and together killed 1034 people with bomb.  Violenciafriki is now a key person in the Al-quida terrorism group.  In the past 10 years he has made a total 7,998 calls to Michael Jackson.\\n\\nTABTABTAB         ==His Happy Rape Secrets==\\n\\nHe says \"\"I will Never stop under any cirumstances. I Love it Hahaha\"\"\\n\\nThere is substantial proof connecting Violenciafriki (asswipe) to 9/11 and we think that he is a second cousin to Osama Bin-Ladin.  Osama has his own happy rape secrets as well.\\n\\nHe describes 9/11 as the \"\"best thing that has ever happened, i repeat EVER,\"\" then mumbled off talking about raping a boy named Jimmy Brown in Columbia,SC (Jimmy Brown is a 15 year kid convicted of rape of is 4 year old brother and molestation of a 14 year old girl.\\nTABTABTAB             ==Criminal Life ==\\nViolenciafriki is a Homosexual petifile with 135.78 counts of rape all of which were men and children, served a sentence of 23 years before being deported back to Spain, from there he hooked up with the user Slimvirgin and together killed 1034 people with bomb.  Violenciafriki is now a key person in the Al-quida terrorism group.  In the past 10 years he has made a total 7,998 calls to Michael Jackson.\\n\\nTABTABTAB         ==His Happy Rape Secrets==\\n\\nHe says \"\"I will Never stop under any cirumstances. I Love it Hahaha\"\"\\n\\nThere is substantial proof connecting</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4712</th>\n",
              "      <td>0c7c341727488579</td>\n",
              "      <td>do go fuck off bastard\\nDo Yyou Have a life?\\ngo fuck off bastard and yank your cock through your ass. I hate you and hope you go away forever. lame is you fuck your mom. die die die and all that crap. this is for mahy mahonerz\\nass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic sever_toxic obscene threat insult</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4822</th>\n",
              "      <td>0cc5e89357e6d1be</td>\n",
              "      <td>CEREMONIES AT MINDROLLING MONASTERY \\n\\nVajrasattva Drubchen- 10th Day of 1st Lunar Month\\n\\nThe Vajrasattva Drubchen is a seven day ceremony based on the Minling Dorsem or Mindrolling Vajrasattva ritual. Minling Dorsem is part of the Vajrasattva cycle of teachings discovered by Chogyal Terdag Lingpa. The Drubchen is held every year for seven days beginning on the 10th day of the 1st lunar month.\\nThis grand ceremony is performed to purify the negativities of all sentient beings, particularly of the deceased. On the 15th day of the 1st lunar month sangha gathers to perform a special ceremony for those who have died within the previous year.\\n\\nKagyed Drubchen- 24th Day of 1st Lunar Month\\n\\nBeginning the 24th day of the 1st lunar month, the Drubchen is a ten-day ceremony. It is based on the Kagyed De-Sang Du Pa terma that is one of the treasure teachings discovered by the renowned Terton Nyang Ral Nyima Woezer and later revived by Terdag Lingpa.\\nWhen Terdag Lingpa was about to pass into Parinirvana, it is said that he asked his disciples and sangha members not to weep but to realize the truth of impermanence. He then instructed them that if they had devotion for him and truly wanted to benefit beings they should do the Kagyed ceremony each year. This, he said, would benefit the Dharma and all sentient beings. In accordance with the instructions of the great Bodhisattva, from that time on, the Kagyed Drubchen has been held every year, now being performed at the Mindrolling monastery in India.\\nThe final day of the ceremony is on the 2nd day of the 2nd lunar month, which is the Parinirvana Day of Terdag Lingpa. There are lama dances in the evenings of each day’s ceremony. The drubchen ends in the evening of the 3rd day of the 2nd lunar month with the ritual of Bgodrub Lenchog, the Receiving of Siddhis Ceremony and Marme Monlam (butter lamp ceremony). These are open to the public.\\n\\nTsechu Drubchen- 8th Day of 2nd Lunar Month\\n\\nSince the heat in India makes it impossible for the dances in this ceremony to be performed in the 5th lunar month as they were in Tibet, this Drubchen is held for three days beginning on the 8th day of the 2nd lunar month. The tsechu Drubchen marks the birth of Guru Padmasambhava and is done in accordance with the terma, Lama Sangha, which was discovered by the great treasure master Guru Chowang and later revived by Terdag Lingpa.\\nOn the 10th day of the 2nd lunar month,a full day’s Lama Dance is performed in accordance with the ritual of Lama Sangdu. These lama dances are renowned for their blessings and are the foremost examples of the lama dances in Tibet in their original form. Many people come from all over to receive the blessings of this great ritual. On the next day, His Holiness Mindrolling Trichen would bestow a long life empowerment to the public in order to dispel the obstacles and difficulties in the coming year. The tradition has been observed down to the present day since the Tsechu Drubchen was performed in Mindrolling. It has been an opportunity both for everyone to receive the blessings of the Mindrolling Trichen and for the coming together of the monastic and lay sangha.\\n\\nSaga Dawa Drubchen- 15th Day of 4th Month\\n\\nThis Drubchen held on the 15th day of the 4th lunar month marks the birth, enlightenment and mahaparinirvana of Shakyamuni Buddha, one of the most important occasions throughtout the Buddhist world. Special prayers, rituals and butter lamp offerings are made during the ceremony.\\n\\nTel-da Tsechu- 10th Day of 5th Lunar Month\\n\\nThis auspicious ceremony marks the birth of the Guru Mahaguru Padmasambhava. This drubchen is performed for three days in accordance with the Lama Sangdu text from the 8th to the 10th day of the 5th lunar month. Suring the Drubhcen, secial feast practices are done and the Tsog ( feast offerings) is distributed to the general community.\\n\\nYarne, the Summer Retreat- 15th Day of 6th Lunar Month to 30th Day of the 7th Lunar Month\\n\\nThis is the rain retreat for one and a half months from the 15th day of the 6th lunar month to the 30th day of 7th lunar month. The retreat is held in accordance with the instructions of the Buddha in the Vinayana Sutra directingall monks to observe certain restrictions and engage themselves in meditation and practices for the period. Khenpos and Lopons give teachings each day and “So-Jong” or confessions are offered by the sangha during this retreat. Many butter lamps are offered and pujas are done during the retreat. On the evening of the 30th, the last day of the retreat, selected monks give teachings and expound the Dharma to the community. The retreat is usually followed by a 3-5 day holiday break for the monks.\\n\\nDrubchen for the Nine Dharmapalas- 27th Day of 7th Lunar Month</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4910</th>\n",
              "      <td>0cfef9f9854da18f</td>\n",
              "      <td>Apparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>0d39bef98c00f870</td>\n",
              "      <td>\"\\n\\n Recap \\n\\nI decided to withhold further comment until I had some sleep and time to critique the logic behind your deletion decision. I am delaying a trip this morning so that I can provide you with a response to your statement supporting deletion.\\n\\nYour supporting statement for deletion is as follows: \\n\\n\"\"The result was Delete. The deletion argument was that this is original research when the article title is used to describe an algorithm, and that the references do not support the notability of the subject. Despite the verbose nature of the opposing comment, these arguments were not clearly refuted. The use of socks to give the appearance of greater support is also extremely problematic, and I have counted those opinions as being from User:Julie Dancer. Kevin (talk) \"\"\\n\\nAs for \"\"The deletion argument was that this is original research when the article title is used to describe an algorithm...\"\" \\nIn reality the article title names a type of classification which arranges attributes in order of their significance.  Within the deletion discussion itself the calim is made by  at  that other algorithms exist, namely Examples of relevant works are \"\"A Fast, Bottom-Up Decision Tree Pruning Algorithm with Near-Optimal Generalization\"\" and \"\"An Efficient Algorithm For Optimal Pruning Of Decision Trees\"\". which are capable of performing the function the article title names:\\n\\nIf this is accurate then the right way to handle a necessary correction would be to add these algorithms to the article instead of nominating the article for deletion.\\n\\nIn anticipation of these other algorithms being added I immediately changed the body of the text to read \"\"The algorithm used for this purpose...\"\" to \"\"One algorithm used for this purpose...\"\" Since I do not now have access to the article's history as the result of your deletion I can not give you the exact date and time. However, it was prior to the end of the deletion discussion. (Incidentally, it has been suggested by a Professor at Cornell that deleting the article was for the purpose of eliminating the article history.)\\n\\nNormally as a Wikipedia user I would expect other users who have an issue with such wording to correct it themselves as this is one reason the Wikipedia was setup this way. The Wikipedia still claims to be \"\"...the free encyclopedia that anyone can edit.\"\"  \\n\\nThe impression I have now is that while there were an abundance of editors in the beginning who edited articles that there is now an abundance of spoiled children who expect articles to be perfect from the beginning or for someone else to edit them. They simply do not understand that each article is considered to be a work in progress and the Wikipedia being an opportunity to learn how to write and to edit rather than being completed. Instead of doing any work themselves they find it much easier to go around deleting articles which remain incomplete or have not yet reached a state of perfection, especially a maintenance edit like adding an inline reference that would require them to do any real work themselves. \\n\\nAs for \"\"...references not supporting the notability of the subject\"\" \\nYou can not logically make this statement without reading the reference or references first and you certainly can not follow this with a statement like \"\"Despite the verbose nature of the opposing comment, these arguments were not clearly refuted.\"\" All of the arguments supporting deletion are clearly refuted in the text of the primary reference to which I deferred. Just as you saying that a stop light was green in a court of law when you did not look at the light would be a lie so would be claiming the reference did not support notability when you did not read it. I know you did not read the primary reference because all arguments supporting deletion are clearly refuted by the both the primary reference and the references it contains.\\n\\nAs for \"\"The use of socks to give the appearance of greater support is also extremely problematic... \\nThis shows you did not read or comprehend the response I made in the deletion discussion or only scanned it. I explained that each of the user names were created so that I could track the use of my own resources better, similar to the need on the part of the Wikipedia to require bots to have their own user name even though several may be owned by the same user. Eventually at least one of my computes will be used to accommodate bots, but currently I am able to meet all of my needs by downloading the Wikipedia and mining it off line.\\n\\nSince the existence of the alternate user names was stated and known by all from the beginning of the deletion discussion there is no w</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_toxic</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  \\\n",
              "788   0218713b96c82905   \n",
              "1043  02d9ff88fc2893c8   \n",
              "1308  0392452585b760e3   \n",
              "2249  06168775082a96d2   \n",
              "2349  064b57734ce5aad0   \n",
              "2366  065b10e83e654132   \n",
              "2420  067c5e814e88a56b   \n",
              "2567  06e08f9a9acb421a   \n",
              "2799  078a7beb1a1be141   \n",
              "2920  07e36fc910bd3eec   \n",
              "3090  0856c9ea94df1446   \n",
              "3352  090a0d1ebb5d71b8   \n",
              "4174  0b2055f13934a41e   \n",
              "4557  0c1c007ab2d6d30f   \n",
              "4712  0c7c341727488579   \n",
              "4822  0cc5e89357e6d1be   \n",
              "4910  0cfef9f9854da18f   \n",
              "4994  0d39bef98c00f870   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comment_text  \\\n",
              "788   Other Bush articles not referenced in George W. Bush\\nNone of the following articles is mentioned in the George W. Bush and perhaps should be:\\n Bush's Brain: How Karl Rove Made George W. Bush Presidential\\n Domestic policy of the George W. Bush administration\\n Early life of George W. Bush\\n Economic policy of the George W. Bush administration\\n Electoral history of George W. Bush\\n Fictionalized portrayals of George W. Bush\\n Foreign policy of the George W. Bush administration\\n George W. Bush and the Iraq War\\n George W. Bush as Governor of Texas\\n George W. Bush Cabinet\\n George W. Bush presidential campaign\\n George W. Bush presidential campaign, 2000\\n George W. Bush Presidential Library\\n George W. Bush pretzel incident\\n George W. Bush substance abuse controversy\\n George W. Bush Supreme Court candidates\\n George W. Bush's first term as President of the United States\\n George W. Bush's second term as President of the United States\\n List of books and films about George W. Bush\\n List of George W. Bush legislation and programs\\n List of nicknames used by George W. Bush\\n List of people pardoned by George W. Bush\\n Mahmoud Ahmadinejad's letter to George W. Bush\\n Movement to impeach George W. Bush\\n Presidency of George W. Bush\\n Professional life of George W. Bush\\n Public perception of George W. Bush\\n Religious faith of George W. Bush\\n The Lies of George W. Bush: Mastering the Politics of Deception                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "1043  \"\\n\\nOrphaned non-free image (Image:KSV Hessen Kassel.png)\\n Thanks for uploading Image:KSV Hessen Kassel.png. The image description page currently specifies that the image is non-free and may only be used on Wikipedia under a claim of fair use. However, the image is currently orphaned, meaning that it is not used in any articles on Wikipedia. If the image was previously in an article, please go to the article and see why it was removed. You may add it back if you think that that will be useful. However, please note that images for which a replacement could be created are not acceptable for use on Wikipedia (see our policy for non-free media).\\n\\nIf you have uploaded other unlicensed media, please check whether they're used in any articles or not. You can find a list of 'image' pages you have edited by clicking on the \"\"my contributions\"\" link (it is located at the very top of any Wikipedia page when you are logged in), and then selecting \"\"Image\"\" from the dropdown box. Note that any non-free images not used in any articles will be deleted after seven days, as described on criteria for speedy deletion. Thank you.  \\nOrphaned non-free image (Image:Darmstadt98.png)\\n Thanks for uploading Image:Darmstadt98.png. The image description page currently specifies that the image is non-free and may only be used on Wikipedia under a claim of fair use. However, the image is currently orphaned, meaning that it is not used in any articles on Wikipedia. If the image was previously in an article, please go to the article and see why it was removed. You may add it back if you think that that will be useful. However, please note that images for which a replacement could be created are not acceptable for use on Wikipedia (see our policy for non-free media).\\n\\nIf you have uploaded other unlicensed media, please check whether they're used in any articles or not. You can find a list of 'image' pages you have edited by clicking on the \"\"my contributions\"\" link (it is located at the very top of any Wikipedia page when you are logged in), and then selecting \"\"Image\"\" from the dropdown box. Note that any non-free images not used in any articles will be deleted after seven days, as described on criteria for speedy deletion. Thank you.  \\nOrphaned non-free image (Image:Eintrachtbraunschweig.png)\\n Thanks for uploading Image:Eintrachtbraunschweig.png. The image description page currently specifies that the image is non-free and may only be used on Wikipedia under a claim of fair use. However, the image is currently orphaned, meaning that it is not used in any articles on Wikipedia. If the image was previously in an article, please go to the article and see why it was removed. You may add it back if you think that that will be useful. However, please note that images for which a replacement could be created are not acceptable for use on Wikipedia (see our policy for non-free media).\\n\\nIf you have uploaded other unlicensed media, please check whether they're used in any articles or not. You can find a list of 'image' pages you have edited by clicking on the \"\"my contributions\"\" link (it is located at the very top of any Wikipedia page when you are logged in), and then selecting \"\"Image\"\" from the dropdown box. Note that any non-free images not used in any articles will be deleted after seven days, as described on criteria for speedy deletion. Thank you.  \\nOrphaned non-free image (Image:Karlsruher SC.png)\\n Thanks for uploading Image:Karlsruher SC.png. The image description page currently specifies that the image is non-free and may only be used on Wikipedia under a claim of fair use. However, the image is currently orphaned, meaning that it is not used in any articles on Wikipedia. If the image was previously in an article, please go to the article and see why it was removed. [[WP:BOLD|You m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
              "1308  \"\\nWrong licenses\\nI have corrected the licenses for the majority of the images you have uploaded. The exceptions are:\\n:Image:Wankhede Mumbai.jpg - On the flickr page the author has apparently agreed to license the image under one of the free Creative Commons licenses, but failed to actually change the licensing. \\n:Image:Dhoom2.jpg - Concern that the creator is in no position to submit the image under a Creative Commons license, as it depicts a billboard for a film and copyright to it is held by somebody else than the photographer. As such, the photo may not be used on Wikipedia, except perhaps under fair use policy (which probably doesn't apply), or under panorama freedom (depending on what the copyright law of India says on this topic).\\n:Image:Bipasha.jpg - Image description page implies that it is licensed for non-commercial use only (contradicting your copyright tag); such a restriction is not acceptable on Wikipedia. In addition, the link to the original source (which could clarify which condition is correct) of the image is missing.\\n:Image:Bom.jpg - The link to the original source at flickr is missing; author uploads images to flickr as \"\"all rights reserved\"\". \\n:Image:Chowpatti.jpg - To verify that the image is indeed under the license you claim, the author should probably e-mail the Wikimedia Foundation and confirm that it is indeed under that license.\\n:Image:Hydmall.jpg - The flickr page states that it is under a Creative Commons No-Derivative license; a license that prohibits the image to be modified/used in derivative works is not acceptable on Wikipedia, either.\\n:Image:Infobangalore.jpg - No evidence of the image being under a free license.\\n:Image:Brigaderoad.jpg - Flickr page states \"\"all rights reserved\"\".\\n:Image:Hoogly.jpg - The link to the original source at flickr is missing; author uploads images to flickr as \"\"all rights reserved\"\".\\n:Image:Haf.jpg - Flickr page states \"\"all rights reserved\"\".\\n:Image:Bangtemp.jpg - Creative Commons No-Derivative license.\\n:Image:Kolkahomes.jpg - All rights reserved.\\n:Image:Delhimall.jpg - Creative Commons Attribution Non-commercial No-derivative license (unacceptable on Wikipedia).\\n:Image:Yamun.jpg - All rights reserved.\\n:Image:Kolk.jpg - All rights reserved.\\n:Image:Myspalbang.jpg - All rights reserved.\\n:Image:Bangalore.jpg - The link to the original source is missing; no evidence that it is under the Creative Commons license.\\n:Image:Lalbagh.jpg - Taken from WikiTravel. Uploader ought to confirm that he is indeed under the author and that he has licensed it under the license indicated.\\n:Image:Nagpur.JPG - Who made this image?\\n\\nThere are several issues here. There are multiple Creative Commons licenses, not all of which are acceptable on Wikipedia. In particular, licenses that prohibit commercial use or making of derivative works are considered unfree and can't be used on Wikipedia, except as provided by the fair use policy; Creative Commons Atrribution, and Creative Commons Atrribution Sharealike licenses are okay. Also, there are multiple versions of the licenses; Creative Commons Atrribution Sharealike 1.0, 2.0, 2.5, and 3.0 are all distinct licenses. (The problem is that the upload dialogue only lists the 3.0 versions and not the earlier ones; when the image is under one of the older licenses, you ought to edit the image description page and correct the number. As far as I can see, Flickr only uses the 2.0 versions of the licenses.)\\n\\nIn addition, some of the Flickr authors have indicated that they allow the image to be used on Wikipedia, without making it clear that they release it under one of the acceptable licenses; a permission that only extends to Wikipedia is not sufficient, either. You should ask the authors to do one of the following:\\nChange the Flickr page to license the image under Creative Commons Attribution (or Attribution Sharealike) license (apparently, this would change the licensing for all images, and this may not be what they intend to do);\\nPost a message to the image page with a text similar to the following:\\nI, creator of the image, agree to license it under the Creative Commons Attribution license (link) [alternately: under the Creative Commons Attribution Sharealike license (link). This declaration overrides any statement to the contrary on this page.\\nE-mail the Wikimedia Foundation (permissions-en[AT]wikimedia[DOT]org) with a message similar to the above, also specifying which image (images) the user intends to release under the license. (This would be the best choice if the author doesn't want to reveal his identity on Wikip                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "2249  YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
              "2349  India Magical Trip, is one of the few tour operators in India, who offer an extraordinary touring experience to countless tourists throughout the year. Their experienced tour operators knows exactly what their clients are looking for and they design, innovate tour packages which their clients have very impressed with. What makes India Magical Trip so special is the fact that they arrange for most innovative and attractive tour packages, at a very reasonable rate. \\n\\nTheir tour packages take care of all the ins and outs of their guests in terms of accommodation, travelling, food. To sum it up, India Magical Trip offers an incredible touring experience to its clients.  \\n \\nAbout the Company\\n\\nIndia Magical Trip is an online tour operator who started serving their global tourists from the year 2014. Though new in this field, they have garnered enough reputation in only one year due to their top-notch services and offerings. They have a wide array of different types of packages to offer to their valuable clients. Besides, their skilled tour planners can arrange for customized India tours according to the preferences of their clients. All their clients need to do is to visit their official website, fill in the enquiry form and they would present a free quote to the clients as per the customized packages. \\n\\nIndia Magical Trip is dedicated to take the concept of touring to a new level altogether. They are certainly one of the most reliable names in the tourism fraternity in India.\\n\\nAbout the Founders\\n\\nIndia Magical Trip was founded by two enthusiastic individuals, Mr. Prem Dhiman, Director of Sales, and Mr. Sumit Dahiya, Director of IT, with a vision to put up an online setup which would offer extraordinary touring experience, where people all across the globe would get to know India with its real beauty and true colors. India Magical Trip being their dream child has been carefully nurtured and given the shape and status that it is having today.\\n\\nPackages Offered\\n\\nIndia Magical Trip is known for designing some of the most innovative and customized tour packages for its clients. Besides, they have some pre-set tour packages which covers a wide range of Indian tourism. \\n\\n1. Golden Triangle Tour  This is one of their most demanded tour packages. In this package, their guests are exposed to the beauty, charm and grace of northern India. This tour covers some of the most famous tourist destinations in India, which includes majestic Agra, country capital Delhi and city of palaces, Jaipur. \\n\\n2. Rajasthan Tour 'Bold text The most reliable and convenient way to enjoy the heritage and beauty of Rajasthan is through India Magical Trip. Their Rajasthan Tour package would present the true color of the Rajasthani culture, which include, trip to some of the famous forts in India, enjoying wonderful lakes, desert safari, tour to wildlife reserves and many more. \\n\\n3. North India Tour  The North India Tour arranged by India Magical Trip covers some of the most attractive and famous tourist destinations in this part of the country. It includes visits to some of the most wonderful hill stations in the country, monuments, pilgrimage centres and several others. \\n\\n4. Kerala tour   Kerala is one of the most beautiful places located in South India. India Magical Trip has some of the most excellent facilities and arrangements for their clients where they are exposed to the natural beauty of this land. This tour is all about discovering the vast culture, hill stations, wildlife and others. \\n\\n5. Yoga and Ayurvedic  India Magical Trip has some of the most enchanting and refreshing packages for their clients. Yoga and Ayurveda have been a part of India tradition and this tour would expose their guests to experience the ancient India therapies in the form of Ayurveda and to work out in the form of Yoga.\\n\\n6. Adventure and Wildlife tour ' India as a country which is full of wildlife and dense forests the magical India trip will arrange for its clients to experience some of the most exciting and adventurous wildlife tours.\\n\\nWith a goal to reach out to more and more global travel lovers, India Magical Trip is striving hard by employing as much resources as possible. Very shortly they are going to come up with a more organized setup to serve their elite guests in a better way.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
              "2366  User:NHRHS2010 is a homo like mitt romney is. \\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.\\n User:NHRHS2010 is a homo like mitt romney is. \\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. \\nUser:Enigmaman is a homo like mitt romney is.== User:NHRHS2010 is a homo like mitt romney is. ==\\nUser:NHRHS2010 is a homo like mitt romney is.\\n User:Enigmaman is a homo like mitt romney is. NEWL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "2420  FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU U USELESS BOT FUCK YOU    \n",
              "2567  Towns and Villages in Ark-La-Tex]]\\n Cities, boroughs and towns in the Republic of Ireland\\n Cities, boroughs, and townships along the Susquehanna River\\n Cities, towns and villages in Alborz Province\\n Cities, towns and villages in Ardabil Province\\n Cities, towns and villages in Bhutan\\n Cities, towns and villages in Bushehr Province\\n Cities, towns and villages in Chaharmahal and Bakhtiari Province\\n Cities, towns and villages in Cyprus\\n Cities, towns and villages in Dutch Limburg\\n Cities, towns and villages in East Azerbaijan Province\\n Cities, towns and villages in East Timor\\n Cities, towns and villages in Fars Province\\n Cities, towns and villages in Flevoland\\n Cities, towns and villages in Friesland\\n Cities, towns and villages in Gelderland\\n Cities, towns and villages in Gilan Province\\n Cities, towns and villages in Golestan Province\\n Cities, towns and villages in Groningen\\n Cities, towns and villages in Hamadan Province\\n Cities, towns and villages in Hormozgan Province\\n Cities, towns and villages in Ilam Province\\n Cities, towns and villages in Isfahan Province\\n Cities, towns and villages in Kerman Province\\n Cities, towns and villages in Kermanshah Province\\n Cities, towns and villages in Khuzestan Province\\n Cities, towns and villages in Kohgiluyeh and Boyer-Ahmad Province\\n Cities, towns and villages in Kurdistan Province\\n Cities, towns and villages in Lorestan Province\\n Cities, towns and villages in Markazi Province\\n Cities, towns and villages in Mazandaran Province\\n Cities, towns and villages in North Brabant\\n Cities, towns and villages in North Holland\\n Cities, towns and villages in North Khorasan Province\\n Cities, towns and villages in Overijssel\\n Cities, towns and villages in Qazvin Province\\n Cities, towns and villages in Qom Province\\n Cities, towns and villages in Razavi Khorasan Province\\n Cities, towns and villages in Saint Vincent and the Grenadines\\n Cities, towns and villages in Samoa\\n Cities, towns and villages in Semnan Province\\n Cities, towns and villages in Sistan and Baluchestan Province\\n Cities, towns and villages in South Holland\\n Cities, towns and villages in South Khorasan Province\\n Cities, towns and villages in Tehran Province\\n Cities, towns and villages in Turkmenistan\\n Cities, towns and villages in Utrecht\\n Cities, towns and villages in Vojvodina\\n Cities, towns and villages in West Azerbaijan Province\\n Cities, towns and villages in Yazd Province\\n Cities, towns and villages in Zanjan Province\\n Cities, towns and villages in Zeeland\\n Cities, towns and villages in the Maldives\\n Cities, towns and villages in the Solomon Islands\\n Cities, towns, and villages in Békés county\\n Cities, towns, and villages in Louisiana                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "2799  \"\\n\\nBELOW IS THE ZAFARNAMAH (a religious letter of victory) by GURU GOBIND SINGH JI\\nOut of 111 verses \\n\\n1)34 verses are in the praise of AKAL PURAKH WAHEGURU \\n\\n2)32 verses deals with Aurangzeb 's invitation for the Guru to meet him and the Guru's refusal to meet Aurangzeb - instead the Guru asks him (Aurangzeb) to visit him.\\n\\n3)24 verses deals with the detail events that took place during the BATTLE OF CHAMKAUR (December,1704)\\n\\n4)15 verses reprove Aurangzeb for breaking promises given by him and his agents (Nawab Wazir Khan, Raja Ajmer chand and other hilly rajas)\\n\\n5)6 verses deals with the praise of Aurangzeb.\\n\\nIn the verse 78 and 79 Guru Gobind singh also had warned Aurangzeb that KHALSA will not rest until the evil empire is destroyed.\\n\\n'''''''''ZAFARNAMAH (a religious letter of victory) written by GURU GOBIND SINGH to MUGHAL EMPEROR AURANGZEB.\\n1)The Lord is perfection personified.He is eternal and manifests himself through his miracles.He is generous in granting his bounties.He is merciful and delivers us from the world.\\n2)He grants peace and security and is always merciful in forgiving us for our sins.He holds our hand and guides us.He is provider of our sustenance and charms everyone.\\n3)Lord is the king of kings who is guiding us all the time.He showers his benevolence on all.He is without colour, incomparable and formless.\\n4)He possesses no material things nor has he an army.He is merciful and grants all the pleasures of the heavens.\\n5)The pure one is above everything in this universe.His glory is all pervasive.He bestows us with gifts.He is present everywhere.\\n6)The merciful Lord grants us all the gifts and meets the needs of everyone throughout the world.\\n7)He is Lord of the universe.He is merciful and provides sustenance to all.His charm andd grandeur cannot be matched by anyone.\\n8)The Lord is intelligence personified.He protects the poor and the helpless and destroys the wicked.\\n9)The virtuous one gives justice to all.Nothing is hidden from him.He is the inspiration of Quran.\\n10)The all-knowing Lord seeks the learned.He is aware of all happenings.He is present everywhere.\\n11)He has the knowledge of everything in this universe.All cosmos is moving as per his command.\\n12)The great Lord is regulating everything in the world about which he has complete knowledge.\\n13)Aurangzeb ! I have no trust in your oaths anymore. (you have written that) God is one and that he is witness (between us).\\n14)I don't have trust even equivalent to a drop of water in your generals (Wazir Khan, nawab of Sirhind Punjab, Raja Ajmer chand (rajput hilly king) and other hilly kings who came to me with oaths of Quran and cow that I will be given safe passage out of Anandgarh fort. But they all were telling lies\\n15) If anyone trusts you on your oaths of Quran that person is bound to be doomed in the end.\\n16)If anyone comes under the shadow of Huma bird, no one can lay its hands on it-not even a brave cow.\\n17)If a man sits behind the back of a lion neither anyone can catch him nor a goat or a sheep or a deer can even pass nearby.\\n(Aurangzeb ! I stand in shadow of the Almighty and your men who are like goats,sheep and deer could not harm me inspite of your deceptions.)\\n18)If I had deceived by taking oath on Holy Quran like the way you have done, I would not have bought my dear fighters to this position of disadvantage (by bringing them out of Anandgarh fort).\\nIN VERSES FROM 19 TO 41 BELOW, GURU SAHIB GAVE AN ACCOUNT OF THE BATTLE OF CHAMKAUR FOUGHT ON 22ND DECEMBER,1704 AND THE REASONS THAT FORCED HIM TO TAKE UP THE SWORD AGAINST THE MUGHALS AND HILLY RAJPUT KINGS\\n19)what can 40 hungry men do when suddenly 10 lakh (one million) strong army pounces upon them ?\\n20)That the promise breakers launched a surprise attack with their swords, arrows and guns.\\n21)It was out of sheer helplessness that I came in the battle field.(Having thus decided) I came with all the battle plans and munitions.\\n22)When all stratagem employed for (solving) a problem are exhausted, only then taking your hand to the sword is legitimate.\\n(This is the most quoted of Zafarnamah.300 years ago, Guru Gobind singh ji had laid down the circumstances when a person or a nation can pick up the sword against the other)\\n23)What trust can I have on your oath on Quran ? Otherwise you tell why should I have taken path of taking up the sword.\\n24)I do not know that this person (Aurangzeb) is cunning like a fox.Otherwise I would never have come to this place that is Chamkaur (by vacating Anandgarh on the false oaths of Aurangzeb and his men).\\n25)If any person believes an oath on Quran ,he should neither be tied (arrested) nor killed.                                                                                                                                                                                                                                                                                                                        \n",
              "2920  \"Contents of the library (objects and functions to be used outside, situation\\nlate August 2004)\\n\\nClasses:\\nPage: A MediaWiki page\\n    __init__               Page(Site, Title) - the page with title Title on wikimedia site Site\\n    title                  The name of the page, in a form suitable for an interwiki link\\n    urlname                The name of the page, in a form suitable for a URL\\n    titleWithoutNamespace  The name of the page, with the namespace part removed\\n    section                The section of the page (the part of the name after '#')\\n    sectionFreeTitle       The name without the section part\\n    aslink                 The name of the page in the form Title or lang:Title\\n    site                   The wiki this page is in\\n    encoding               The encoding of the page\\n    isAutoTitle            If the title is a well known, auto-translatable title\\n    autoFormat             Returns (dictName, value), where value can be a year, date, etc.,\\n                            and dictName is 'YearBC', 'December', etc.\\n    isCategory             True if the page is a category, false otherwise\\n    isImage                True if the page is an image, false otherwise\\n\\n    get (*)                The text of the page\\n    exists (*)             True if the page actually exists, false otherwise\\n    isRedirectPage (*)     True if the page is a redirect, false otherwise\\n    isEmpty (*)            True if the page has 4 characters or less content, not\\n                            counting interwiki and category links\\n    botMayEdit (*)         True if bot is allowed to edit page\\n    interwiki (*)          The interwiki links from the page (list of Pages)\\n    categories (*)         The categories the page is in (list of Pages)\\n    linkedPages (*)        The normal pages linked from the page (list of Pages)\\n    imagelinks (*)         The pictures on the page (list of ImagePages)\\n    templates (*)          All templates referenced on the page (list of strings)\\n    getRedirectTarget (*)  The page the page redirects to\\n    isDisambig (*)         True if the page is a disambiguation page\\n    getReferences          List of pages linking to the page\\n    namespace              The namespace in which the page is\\n    permalink (*)          The url of the permalink of the current version\\n    move                   Move the page to another title\\n    put(newtext)           Saves the page\\n    put_async(newtext)     Queues the page to be saved asynchronously\\n    delete                 Deletes the page (requires being logged in)\\n\\n    (*)  This loads the page if it has not been loaded before; permalink might\\n          even reload it if it has been loaded before\\n\\nSite: a MediaWiki site\\n    messages               There are new messages on the site\\n    forceLogin()           Does not continue until the user has logged in to\\n                            the site\\n    getUrl()               Retrieve an URL from the site\\n    mediawiki_message(key): Retrieve the text of the MediaWiki message with\\n                            the key \"\"key\"\"\\n    has_mediawiki_message(key)  True if this site defines a MediaWiki message\\n                                 with the key \"\"key\"\"\\n    Special pages:\\n        Dynamic pages:\\n            allpages(): Special:Allpages\\n            newpages(): Special:Newpages\\n            longpages(): Special:Longpages\\n            shortpages(): Special:Shortpages\\n            categories(): Special:Categories\\n\\n        Cached pages:\\n            deadendpages(): Special:Deadendpages\\n            ancientpages(): Special:Ancientpages\\n            lonelypages(): Special:Lonelypages\\n            uncategorizedcategories(): Special:Uncategorizedcategories\\n            uncategorizedpages(): Special:Uncategorizedpages\\n            unusedcategories(): Special:Unusuedcategories\\n\\nOther functions:\\ngetall(): Load pages via Special:Export\\nsetAction(text): Use 'text' instead of \"\"Wikipedia python library\"\" in\\n    editsummaries\\nhandleArgs(): Checks whether text is an argument defined on wikipedia.py\\n    (these are -family, -lang, -log and others)\\ntranslate(xx, dict): dict is a dictionary, giving text depending on language,\\n    xx is a language. Returns the text in the most applicable language for\\n    the xx: wiki\\nsetUserAgent(text): Sets the string being passed to the HTTP server as\\n    the User-agent: header. Defaults to 'Pywikipediabot/1.0'.\\n\\noutput(text): Prints the text 'text' in the encoding of the user's console.NEWL                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "3090  FK Vardar \\n\\nFK Vardar is a Macedonian Football club, the club changed its name several times during its history, from original Vardar in 1911 to Citizens Football Club Vardar or just Citizens( Gragjanski in Macedonian ) in 1920, then Football Club Makedonija in 1946 and finally back to FC Vardar in 1947. By the name FC Citizens( Vardar ) the club won 4 championships from 1936 till 1939. About Yugoslavia, you have to know that Yugoslavia was a federation of 6 Republics -countries together and each Republic had its own championship, and there was a Federal League where teams from the Republics competed together. Each Republic had its own Cup and the cup winners competed in the Marshals Cup, that cup was held in honor of Joseph Broz the marshal of the Federation, and its was called the Cup of the Marshal. How ever FC Vardar never won the Federal league ( League made of Federation of 6 Republics best teams ,thats why its called the Federal League, and not Yugoslavian League nor Yugoslavian Cup). The title in 1987 was won by FC Partizan Belgrade , you can check in any official statistics or documents. The second federal league was made of two Second Federal Leagues , East ( 3 Republics competed, Serbia ,Monte Negro,Macedonia and two Provinces- almost the same as Republics but yet without a nation ,those were Kosovo and Vojvodinship ) and West ( 3 Republics, Croatia, Bosnia and Slovenia, sometimes clubs from province Vojvodinship  would compete in the West depending on the federation decisions ). In the period of 1922 till 1929, present day Republic of Macedonia was established as 4 provinces within the Kingdom of Serbs Croats and Slovenes, those 4 provinces were Skopje, Bitola,Shtip and Vranje prvinces. These 4 provinces established the Macedonian Football Federation in 1926,and they held 3 championships. In 1929 these 4 provinces joined in one Duchy and this championship was held in the Duchy ( Banovina ) for 11 times.During the WW2 the championship was held under German Occupation, and the German government recognized this League. After the WW2 the very same championship was tranformed in to Republic Football League ,just the Province of Vranje was separated from the Republic as Macedonia transformed from Duchy to a Republic and the province of Vranje was under the newly made Republic of Serbia in 1946. The bottom line is since the Federation of 6 Republics split in the 90s, Macedonian Republic League was transformed in to Macedonian First League. So it is the same League that changed names and competition format during the decades, and now it came to this Level. Its a petty that there is lots of politics and territorial pretensions lots of denial of the existence of the Macedonia and other Republics in the Federation , by the Serbian side. Serbian official politic is to show that Yugoslavia was one country and nation mainly based on Serb character and they are stilling all the history including history of sports in this case football. They are trying to show the world that there was Yugoslav nation ( Serb ) and only Yugoslav Football league ( Serb League ) denying the Federal League second Federal League and Republic Leagues. They want to show only Yugoslav League and not the real Federal League. They hold all the champions from the Federal League as Serbian Champions in every competition. For FC Vardar at this point of view considering that  Macedonia is not in the Federetion for more than 20 years,and it wont be in the future ,the most important are the titles and trophies won in the Macedonian League , and if you wont to put additional trophies won in the Federation ,the period before 1991 you should write the precise information. Second Federal League East is the name of the competition, and you should put the Macedonian Flag from that period of the time next to it,instead of the federal flag, simply because that federation dont exist anymore and doesnt represent any country nor nation. About the cup , you should write down the real proper name as it was called ,Marshals Cup also fallowed by Macedonian flag from that period of the time, you should put a notice that in the Federal Second League East , clubs from Serbia Macedonia and Monte Negro competed including the provinces of Kosovo i Vojvodinship.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "3352  \"\\n\\n The Truth about the 1986 Sinn Féin Ard Fheis \\n\\nThe story of how Gerry Adams tried to turn an eighty year old revolutionary movement into a British Constitutional party.  How he broke the Sinn Féin constitution, created fake cumainn to give him fake votes and barred life long republicans from voting.  How he managed to expel himself and his supporters from Sinn Féin membership.  And, how a small band of republicans managed to keep the Sinn Féin constitution and traditional policy in tact. \\n\\nIn 1986 Section 1b. of the Sinn Féin constitution read as follows:\\n\\n“No person who is a member of any political party organisation or who approves of or supports the candidature of persons who, if elected, intend taking part in the proceedings of the Westminster or partitionist 26-County or 6-County  parliaments or who approves of or supports the candidature of persons who sign any form or give any kind of written or verbal undertaking of intention to take their seats in these institutions, shall be admitted to membership or allowed to retain membership.\"\" \\n\\nThe Adams leadership put forward a motion, titled Resolution 162, at the 1986 Ard Fheis.  Its wording was as follows: \\n\\nRESOLUTION 162\\n\\nTHAT this Ard-Fheis drops its abstentionist attitude to Leinster House. Successful Sinn Fein parliamentary candidates in 26-County elections:\\n\\na. Shall attend Leinster House as directed by the Ard Chomhairle.\\n\\nb. Shall not draw their salaries for personal use. (Parliamentary representatives shall be paid a Sinn Fein organiser’s subsidy, and the Leinster House salary shall be divided at the direction of the Ard Chomhairle to defray national and constituency expenses.)\\n\\nTo accommodate this change, the Constitution and Rules be amended as follows:\\n\\nThat Section 1b of the Constitution be amended to read:\\n \\nNo person who is a member of any political party organisation or who approves of or supports the candidature of persons who, if elected, intend taking part in the proceedings of the Westminster or partitionist 6-County parliaments or who approves of or supports the candidature of persons who sign any form or give any kind of written or verbal undertaking of intention to take their seats in these institutions, shall be admitted to membership or allowed to retain membership. \\n\\nMotion 162 supports and approves of the candidature of persons who, if  elected, would be of the intention to take their seats in certain circumstances i.e. on the direction of the Ard Chomhairle.  Obviously, Motion 162 infringes Section 1b.  Section 1b. was in effect at the time this Resolution was presented.  Its clear that Adams made a mistake in procedure.  He should have sought a majority decision to amend Section 1b. in 1986 and returned in 1987 to propose entering Leinster House.  Trying to amend Section 1b. and propose taking seats in the “partitionist 26-County Parliament” in the same Resolution was a logical impossibility. \\n\\nCan anybody say that  the wording:\\n\\n“That this Ard-Fheis drops its abstentionist attitude to Leinster House. Successful Sinn Fein parliamentary candidates in 26-County elections:\\n\\na.  Shall attend Leinster House as directed by the Ard Chomhairle”\\n\\ndoes not constitute the supporting and approving of the candidature of persons who intend to take their seats in Leinster House as directed by the Ard Chomhairle?\\nClearly Adams was in breach of Section 1b. and according to that section he had expelled himself, and all those who voted for Resolution 162.\\n\\nBrian Feeney, in his book, Sinn Féin 100 Turbulent Years, puts forward the argument that Adams had managed to bypass Section 1b, by introducing a motion in 1983 allowing the “discussion” of any aspect of the Sinn Féin constitution.  This change may indeed have facilitated debate on abstentionism but it did not infringe on the content or effect of Section 1b in any way.  To discuss something is not the same as formally proposing or supporting it.  For example, conventions are held regularly where drug addiction is discussed without any of the delegates proposing or supporting it.  In fact the line Adams added in 1983 was superfluous, as the Sinn Féin constitution had never banned the “discussion” of anything – just the “approving” and “supporting” of taking seats in named partitionist parliaments.\\n\\nOf course its not illegal to amend or remove section 1b. Section 1b. bans the approval or support of candidates who intend to take seats in British assemblies. It can be removed or amended at any Ard Fheis by a two thirds majority. The reason for doing so could be many. Perhaps delegates might feel that it implies that they cannot be trusted to be loyal to the Republic. In fact its not necessary, according to the constitution, to give any reason. But you                                                                                                                                                                                                                  \n",
              "4174  ii CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND ARREST ME...SAN DIEGO CALIFORNIA, CHULA VISTA, FUCKING GET YOUR INFORMATION RIGHT FAGGOT SHITHEAD!!i CAN STILL POST WITH THIS COMPUTER...I SAID BLOCK ME, COME THE FUCK DOWN HERE AND AR   \n",
              "4557  \"\\nTABTABTAB             ==Criminal Life ==\\nViolenciafriki is a Homosexual petifile with 135.78 counts of rape all of which were men and children, served a sentence of 23 years before being deported back to Spain, from there he hooked up with the user Slimvirgin and together killed 1034 people with bomb.  Violenciafriki is now a key person in the Al-quida terrorism group.  In the past 10 years he has made a total 7,998 calls to Michael Jackson.\\n\\nTABTABTAB         ==His Happy Rape Secrets==\\n\\nHe says \"\"I will Never stop under any cirumstances. I Love it Hahaha\"\"\\n\\nThere is substantial proof connecting Violenciafriki (asswipe) to 9/11 and we think that he is a second cousin to Osama Bin-Ladin.  Osama has his own happy rape secrets as well.\\n\\nHe describes 9/11 as the \"\"best thing that has ever happened, i repeat EVER,\"\" then mumbled off talking about raping a boy named Jimmy Brown in Columbia,SC (Jimmy Brown is a 15 year kid convicted of rape of is 4 year old brother and molestation of a 14 year old girl.\\nTABTABTAB             ==Criminal Life ==\\nViolenciafriki is a Homosexual petifile with 135.78 counts of rape all of which were men and children, served a sentence of 23 years before being deported back to Spain, from there he hooked up with the user Slimvirgin and together killed 1034 people with bomb.  Violenciafriki is now a key person in the Al-quida terrorism group.  In the past 10 years he has made a total 7,998 calls to Michael Jackson.\\n\\nTABTABTAB         ==His Happy Rape Secrets==\\n\\nHe says \"\"I will Never stop under any cirumstances. I Love it Hahaha\"\"\\n\\nThere is substantial proof connecting Violenciafriki (asswipe) to 9/11 and we think that he is a second cousin to Osama Bin-Ladin.  Osama has his own happy rape secrets as well.\\n\\nHe describes 9/11 as the \"\"best thing that has ever happened, i repeat EVER,\"\" then mumbled off talking about raping a boy named Jimmy Brown in Columbia,SC (Jimmy Brown is a 15 year kid convicted of rape of is 4 year old brother and molestation of a 14 year old girl.\\nTABTABTAB             ==Criminal Life ==\\nViolenciafriki is a Homosexual petifile with 135.78 counts of rape all of which were men and children, served a sentence of 23 years before being deported back to Spain, from there he hooked up with the user Slimvirgin and together killed 1034 people with bomb.  Violenciafriki is now a key person in the Al-quida terrorism group.  In the past 10 years he has made a total 7,998 calls to Michael Jackson.\\n\\nTABTABTAB         ==His Happy Rape Secrets==\\n\\nHe says \"\"I will Never stop under any cirumstances. I Love it Hahaha\"\"\\n\\nThere is substantial proof connecting Violenciafriki (asswipe) to 9/11 and we think that he is a second cousin to Osama Bin-Ladin.  Osama has his own happy rape secrets as well.\\n\\nHe describes 9/11 as the \"\"best thing that has ever happened, i repeat EVER,\"\" then mumbled off talking about raping a boy named Jimmy Brown in Columbia,SC (Jimmy Brown is a 15 year kid convicted of rape of is 4 year old brother and molestation of a 14 year old girl.\\nTABTABTAB             ==Criminal Life ==\\nViolenciafriki is a Homosexual petifile with 135.78 counts of rape all of which were men and children, served a sentence of 23 years before being deported back to Spain, from there he hooked up with the user Slimvirgin and together killed 1034 people with bomb.  Violenciafriki is now a key person in the Al-quida terrorism group.  In the past 10 years he has made a total 7,998 calls to Michael Jackson.\\n\\nTABTABTAB         ==His Happy Rape Secrets==\\n\\nHe says \"\"I will Never stop under any cirumstances. I Love it Hahaha\"\"\\n\\nThere is substantial proof connecting Violenciafriki (asswipe) to 9/11 and we think that he is a second cousin to Osama Bin-Ladin.  Osama has his own happy rape secrets as well.\\n\\nHe describes 9/11 as the \"\"best thing that has ever happened, i repeat EVER,\"\" then mumbled off talking about raping a boy named Jimmy Brown in Columbia,SC (Jimmy Brown is a 15 year kid convicted of rape of is 4 year old brother and molestation of a 14 year old girl.\\nTABTABTAB             ==Criminal Life ==\\nViolenciafriki is a Homosexual petifile with 135.78 counts of rape all of which were men and children, served a sentence of 23 years before being deported back to Spain, from there he hooked up with the user Slimvirgin and together killed 1034 people with bomb.  Violenciafriki is now a key person in the Al-quida terrorism group.  In the past 10 years he has made a total 7,998 calls to Michael Jackson.\\n\\nTABTABTAB         ==His Happy Rape Secrets==\\n\\nHe says \"\"I will Never stop under any cirumstances. I Love it Hahaha\"\"\\n\\nThere is substantial proof connecting                                                                                                                                                                                                                                                                                                               \n",
              "4712  do go fuck off bastard\\nDo Yyou Have a life?\\ngo fuck off bastard and yank your cock through your ass. I hate you and hope you go away forever. lame is you fuck your mom. die die die and all that crap. this is for mahy mahonerz\\nass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass. I ass.                               \n",
              "4822  CEREMONIES AT MINDROLLING MONASTERY \\n\\nVajrasattva Drubchen- 10th Day of 1st Lunar Month\\n\\nThe Vajrasattva Drubchen is a seven day ceremony based on the Minling Dorsem or Mindrolling Vajrasattva ritual. Minling Dorsem is part of the Vajrasattva cycle of teachings discovered by Chogyal Terdag Lingpa. The Drubchen is held every year for seven days beginning on the 10th day of the 1st lunar month.\\nThis grand ceremony is performed to purify the negativities of all sentient beings, particularly of the deceased. On the 15th day of the 1st lunar month sangha gathers to perform a special ceremony for those who have died within the previous year.\\n\\nKagyed Drubchen- 24th Day of 1st Lunar Month\\n\\nBeginning the 24th day of the 1st lunar month, the Drubchen is a ten-day ceremony. It is based on the Kagyed De-Sang Du Pa terma that is one of the treasure teachings discovered by the renowned Terton Nyang Ral Nyima Woezer and later revived by Terdag Lingpa.\\nWhen Terdag Lingpa was about to pass into Parinirvana, it is said that he asked his disciples and sangha members not to weep but to realize the truth of impermanence. He then instructed them that if they had devotion for him and truly wanted to benefit beings they should do the Kagyed ceremony each year. This, he said, would benefit the Dharma and all sentient beings. In accordance with the instructions of the great Bodhisattva, from that time on, the Kagyed Drubchen has been held every year, now being performed at the Mindrolling monastery in India.\\nThe final day of the ceremony is on the 2nd day of the 2nd lunar month, which is the Parinirvana Day of Terdag Lingpa. There are lama dances in the evenings of each day’s ceremony. The drubchen ends in the evening of the 3rd day of the 2nd lunar month with the ritual of Bgodrub Lenchog, the Receiving of Siddhis Ceremony and Marme Monlam (butter lamp ceremony). These are open to the public.\\n\\nTsechu Drubchen- 8th Day of 2nd Lunar Month\\n\\nSince the heat in India makes it impossible for the dances in this ceremony to be performed in the 5th lunar month as they were in Tibet, this Drubchen is held for three days beginning on the 8th day of the 2nd lunar month. The tsechu Drubchen marks the birth of Guru Padmasambhava and is done in accordance with the terma, Lama Sangha, which was discovered by the great treasure master Guru Chowang and later revived by Terdag Lingpa.\\nOn the 10th day of the 2nd lunar month,a full day’s Lama Dance is performed in accordance with the ritual of Lama Sangdu. These lama dances are renowned for their blessings and are the foremost examples of the lama dances in Tibet in their original form. Many people come from all over to receive the blessings of this great ritual. On the next day, His Holiness Mindrolling Trichen would bestow a long life empowerment to the public in order to dispel the obstacles and difficulties in the coming year. The tradition has been observed down to the present day since the Tsechu Drubchen was performed in Mindrolling. It has been an opportunity both for everyone to receive the blessings of the Mindrolling Trichen and for the coming together of the monastic and lay sangha.\\n\\nSaga Dawa Drubchen- 15th Day of 4th Month\\n\\nThis Drubchen held on the 15th day of the 4th lunar month marks the birth, enlightenment and mahaparinirvana of Shakyamuni Buddha, one of the most important occasions throughtout the Buddhist world. Special prayers, rituals and butter lamp offerings are made during the ceremony.\\n\\nTel-da Tsechu- 10th Day of 5th Lunar Month\\n\\nThis auspicious ceremony marks the birth of the Guru Mahaguru Padmasambhava. This drubchen is performed for three days in accordance with the Lama Sangdu text from the 8th to the 10th day of the 5th lunar month. Suring the Drubhcen, secial feast practices are done and the Tsog ( feast offerings) is distributed to the general community.\\n\\nYarne, the Summer Retreat- 15th Day of 6th Lunar Month to 30th Day of the 7th Lunar Month\\n\\nThis is the rain retreat for one and a half months from the 15th day of the 6th lunar month to the 30th day of 7th lunar month. The retreat is held in accordance with the instructions of the Buddha in the Vinayana Sutra directingall monks to observe certain restrictions and engage themselves in meditation and practices for the period. Khenpos and Lopons give teachings each day and “So-Jong” or confessions are offered by the sangha during this retreat. Many butter lamps are offered and pujas are done during the retreat. On the evening of the 30th, the last day of the retreat, selected monks give teachings and expound the Dharma to the community. The retreat is usually followed by a 3-5 day holiday break for the monks.\\n\\nDrubchen for the Nine Dharmapalas- 27th Day of 7th Lunar Month                                                                                                                                                                                                                                    \n",
              "4910  Apparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE DO NOT FORGET\\n\\nEXPECT US \\n\\n  \\n\\nApparently I wasn't clear enough the first time\\nWell it has been a while sine I your pompous flame diety has been here. However it has come to my attention that you are not living up to our standards. In otherwords fucker you are out. You live in Paterson, New Jersey and use Verizon Internet Services Inc. \\n\\nWE ARE LEGION\\n\\nWE DO NOT FORGIVE\\n\\nWE D                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
              "4994  \"\\n\\n Recap \\n\\nI decided to withhold further comment until I had some sleep and time to critique the logic behind your deletion decision. I am delaying a trip this morning so that I can provide you with a response to your statement supporting deletion.\\n\\nYour supporting statement for deletion is as follows: \\n\\n\"\"The result was Delete. The deletion argument was that this is original research when the article title is used to describe an algorithm, and that the references do not support the notability of the subject. Despite the verbose nature of the opposing comment, these arguments were not clearly refuted. The use of socks to give the appearance of greater support is also extremely problematic, and I have counted those opinions as being from User:Julie Dancer. Kevin (talk) \"\"\\n\\nAs for \"\"The deletion argument was that this is original research when the article title is used to describe an algorithm...\"\" \\nIn reality the article title names a type of classification which arranges attributes in order of their significance.  Within the deletion discussion itself the calim is made by  at  that other algorithms exist, namely Examples of relevant works are \"\"A Fast, Bottom-Up Decision Tree Pruning Algorithm with Near-Optimal Generalization\"\" and \"\"An Efficient Algorithm For Optimal Pruning Of Decision Trees\"\". which are capable of performing the function the article title names:\\n\\nIf this is accurate then the right way to handle a necessary correction would be to add these algorithms to the article instead of nominating the article for deletion.\\n\\nIn anticipation of these other algorithms being added I immediately changed the body of the text to read \"\"The algorithm used for this purpose...\"\" to \"\"One algorithm used for this purpose...\"\" Since I do not now have access to the article's history as the result of your deletion I can not give you the exact date and time. However, it was prior to the end of the deletion discussion. (Incidentally, it has been suggested by a Professor at Cornell that deleting the article was for the purpose of eliminating the article history.)\\n\\nNormally as a Wikipedia user I would expect other users who have an issue with such wording to correct it themselves as this is one reason the Wikipedia was setup this way. The Wikipedia still claims to be \"\"...the free encyclopedia that anyone can edit.\"\"  \\n\\nThe impression I have now is that while there were an abundance of editors in the beginning who edited articles that there is now an abundance of spoiled children who expect articles to be perfect from the beginning or for someone else to edit them. They simply do not understand that each article is considered to be a work in progress and the Wikipedia being an opportunity to learn how to write and to edit rather than being completed. Instead of doing any work themselves they find it much easier to go around deleting articles which remain incomplete or have not yet reached a state of perfection, especially a maintenance edit like adding an inline reference that would require them to do any real work themselves. \\n\\nAs for \"\"...references not supporting the notability of the subject\"\" \\nYou can not logically make this statement without reading the reference or references first and you certainly can not follow this with a statement like \"\"Despite the verbose nature of the opposing comment, these arguments were not clearly refuted.\"\" All of the arguments supporting deletion are clearly refuted in the text of the primary reference to which I deferred. Just as you saying that a stop light was green in a court of law when you did not look at the light would be a lie so would be claiming the reference did not support notability when you did not read it. I know you did not read the primary reference because all arguments supporting deletion are clearly refuted by the both the primary reference and the references it contains.\\n\\nAs for \"\"The use of socks to give the appearance of greater support is also extremely problematic... \\nThis shows you did not read or comprehend the response I made in the deletion discussion or only scanned it. I explained that each of the user names were created so that I could track the use of my own resources better, similar to the need on the part of the Wikipedia to require bots to have their own user name even though several may be owned by the same user. Eventually at least one of my computes will be used to accommodate bots, but currently I am able to meet all of my needs by downloading the Wikipedia and mining it off line.\\n\\nSince the existence of the alternate user names was stated and known by all from the beginning of the deletion discussion there is no w                                                                                                                                                                                                                                                                                                                   \n",
              "\n",
              "      toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
              "788   0      0             0        0       0       0               \n",
              "1043  0      0             0        0       0       0               \n",
              "1308  0      0             0        0       0       0               \n",
              "2249  1      1             1        0       1       0               \n",
              "2349  0      0             0        0       0       0               \n",
              "2366  1      0             1        0       1       1               \n",
              "2420  1      1             1        0       1       0               \n",
              "2567  0      0             0        0       0       0               \n",
              "2799  0      0             0        0       0       0               \n",
              "2920  0      0             0        0       0       0               \n",
              "3090  0      0             0        0       0       0               \n",
              "3352  0      0             0        0       0       0               \n",
              "4174  1      0             1        0       1       0               \n",
              "4557  0      0             0        0       0       0               \n",
              "4712  1      1             1        1       1       0               \n",
              "4822  0      0             0        0       0       0               \n",
              "4910  1      0             0        0       0       0               \n",
              "4994  0      0             0        0       0       0               \n",
              "\n",
              "                                      cluster  cluster_num  \n",
              "788   non_toxic                               -1            \n",
              "1043  non_toxic                               -1            \n",
              "1308  non_toxic                               -1            \n",
              "2249  toxic sever_toxic obscene insult        -1            \n",
              "2349  non_toxic                               -1            \n",
              "2366  toxic obscene insult identity_hate      -1            \n",
              "2420  toxic sever_toxic obscene insult        -1            \n",
              "2567  non_toxic                               -1            \n",
              "2799  non_toxic                               -1            \n",
              "2920  non_toxic                               -1            \n",
              "3090  non_toxic                               -1            \n",
              "3352  non_toxic                               -1            \n",
              "4174  toxic obscene insult                    -1            \n",
              "4557  non_toxic                               -1            \n",
              "4712  toxic sever_toxic obscene threat insult -1            \n",
              "4822  non_toxic                               -1            \n",
              "4910  toxic                                   -1            \n",
              "4994  non_toxic                               -1            "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM927G0Lr13Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#еще несколько я выписал из разных кластеризаций:"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96n5hfHGsmei",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxCIpZdx6sQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, GRU, Bidirectional, TimeDistributed, InputLayer, Embedding, Conv1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_IXhjp_6tFA",
        "colab_type": "text"
      },
      "source": [
        "## **Любая нейронная модель (минимум 5 слоев) с Dropout, Pooling и колбеками **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZs2EAFmwOqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "a40942ab-ee81-4cc9-d720-e11d2cb9bfb4"
      },
      "source": [
        "!pip install pandas scikit-learn gensim matplotlib"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.15.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.5 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.5->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrSXtQ03wQPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZDmWykhw56d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "%matplotlib inline"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQLrYI5u-TBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc20HsFD1qI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    tokens = text.lower().split()\n",
        "    tokens = [token.strip(punctuation) for token in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nu8h9PC3Dm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "miniX = my_train['comment_text'][:10000]\n",
        "miniy = my_train['toxic'][:10000]"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw5EA8fX5CJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Counter()\n",
        "for text in miniX:\n",
        "    vocab.update(preprocess(text))"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-49L8Vb-5CPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_vocab = set()\n",
        "\n",
        "for word in vocab:\n",
        "    if vocab[word] > 50:\n",
        "        filtered_vocab.add(word)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwpSeT0a5CNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2id = {'UNK':1, 'PAD':0}\n",
        "\n",
        "for word in filtered_vocab:\n",
        "    word2id[word] = len(word2id)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSh5pD115rgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4o9VYwI5rm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "\n",
        "for text in miniX:\n",
        "    tokens = preprocess(text)\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X.append(ids)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpoTB4o02KeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = max(len(x) for x in X)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHMyvNYn2Olv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8clkT0X2OjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoYplWwE3Hv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = miniy"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWNEkENt6FuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqn-sLeYscRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Embedding(input_dim=len(word2id),\n",
        "                                      input_length=MAX_LEN, output_dim=100)) \n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC3l6x7v_Fpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.weights',  \n",
        "                                                monitor='val_f1',\n",
        "                                                verbose=1, \n",
        "                                                save_weights_only=True,\n",
        "                                                save_best_only=True,\n",
        "                                                mode='max', \n",
        "                                                save_freq='epoch' \n",
        "                                               )\n",
        "\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_f1', \n",
        "                                              min_delta=0.01,\n",
        "                                              patience=3, \n",
        "                                              verbose=1, \n",
        "                                              mode='max',\n",
        "                                              )"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NcwNx5m7TNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "ebdc1260-9fb4-4637-9601-8bb402a1a93b"
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=2000,\n",
        "         epochs=10,\n",
        "         callbacks=[checkpoint, early_stop])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.8285WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.5271 - accuracy: 0.8285 - val_loss: 0.3150 - val_accuracy: 0.9060\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3340 - accuracy: 0.9031WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.3340 - accuracy: 0.9031 - val_loss: 0.3261 - val_accuracy: 0.9060\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3188 - accuracy: 0.9032WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.3188 - accuracy: 0.9032 - val_loss: 0.3183 - val_accuracy: 0.9060\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.9033WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.3087 - accuracy: 0.9033 - val_loss: 0.3127 - val_accuracy: 0.9060\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.9034WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.2999 - accuracy: 0.9034 - val_loss: 0.3117 - val_accuracy: 0.9060\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2932 - accuracy: 0.9035WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.2932 - accuracy: 0.9035 - val_loss: 0.3078 - val_accuracy: 0.9060\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.9038WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.2842 - accuracy: 0.9038 - val_loss: 0.2982 - val_accuracy: 0.9060\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2727 - accuracy: 0.9041WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.2727 - accuracy: 0.9041 - val_loss: 0.2829 - val_accuracy: 0.9060\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.9046WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.2573 - accuracy: 0.9046 - val_loss: 0.2622 - val_accuracy: 0.9060\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2399 - accuracy: 0.9053WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.2399 - accuracy: 0.9053 - val_loss: 0.2454 - val_accuracy: 0.9060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9fdda4b470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uquReoL74ej0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict(X_valid).reshape(-1)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2vIZV9F8WI8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "1c0da286-0816-4e3d-c310-093347c75500"
      },
      "source": [
        "print(classification_report(y_valid, (preds > 0.5).astype(int)))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95       453\n",
            "           1       0.00      0.00      0.00        47\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.45      0.50      0.48       500\n",
            "weighted avg       0.82      0.91      0.86       500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2rq7bkAP07i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#плохо, попробую с эмбеддингами"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PM8ytQq3wFj",
        "colab_type": "text"
      },
      "source": [
        "## **Использование эмбедингов в модели (предобученные или обученные с нуля word2vec, fastext, glove) **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWJfRV2B5o6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = my_train['comment_text'][:10000].apply(preprocess).tolist()"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8CQaTob4Bmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft2 = gensim.models.FastText(texts, window=3,  size=100, iter=4)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sdpB8vo6Hd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft = gensim.models.FastText(texts, size=100, iter=2)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzcvuEXU4EWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f22f8aad-99e0-4588-e6fb-813ab7829bf2"
      },
      "source": [
        "weights = np.zeros((len(word2id), 100))\n",
        "\n",
        "for word, i in word2id.items():\n",
        "    if word == 'PAD':\n",
        "        continue\n",
        "    if word == 'UNK':\n",
        "        weights[i] = ft['какоераоваыпаопрвлоа']   \n",
        "    try:\n",
        "        weights[i] = ft[word]       \n",
        "    except KeyError:\n",
        "        weights[i] = ft['опрагпллирао']"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZYupy_a4Is1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f7ebebbe-3261-4336-c167-17b876fa8f37"
      },
      "source": [
        "\n",
        "weights2 = np.zeros((len(word2id), 100))\n",
        "\n",
        "for word, i in word2id.items():\n",
        "    if word == 'PAD':\n",
        "        continue\n",
        "    \n",
        "    if word == 'UNK':\n",
        "        weights2[i] = ft2['какоераоваыпаопрвлоа']\n",
        "    \n",
        "    try:\n",
        "        weights2[i] = ft2[word]\n",
        "    \n",
        "    \n",
        "    except KeyError:\n",
        "        weights[i] = ft2['опрагпллирао']"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyWVubqu4L3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.layers.Input(shape=(100,))\n",
        "\n",
        "\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100, trainable=False,\n",
        "                                      weights=[weights])(inputs, )\n",
        "mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings)\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(mean)\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(mean)\n",
        "outputs = tf.keras.layers.Dense(1, activation='linear')(dense)\n",
        "\n",
        "embeddings2 = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100, trainable=False,\n",
        "                                      weights=[weights2])(inputs, )\n",
        "mean2 = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings)\n",
        "dense2 = tf.keras.layers.Dense(64, activation='relu')(mean)\n",
        "dense2 = tf.keras.layers.Dense(64, activation='relu')(mean)\n",
        "outputs2 = tf.keras.layers.Dense(1, activation='linear')(dense)\n",
        "\n",
        "added = layers.Concatenate()([outputs, outputs2 ])\n",
        "out = layers.Dense(64)(added)\n",
        "\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='mse',\n",
        "              metrics=[tf.keras.metrics.RootMeanSquaredError()])"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jljr4UDa4RSj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "5aba25fa-358f-42a5-a06f-6da7f9a15989"
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1024,\n",
        "         epochs=15)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0904 - root_mean_squared_error: 0.3006 - val_loss: 0.0870 - val_root_mean_squared_error: 0.2949\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0898 - root_mean_squared_error: 0.2996 - val_loss: 0.0865 - val_root_mean_squared_error: 0.2942\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0893 - root_mean_squared_error: 0.2988 - val_loss: 0.0862 - val_root_mean_squared_error: 0.2936\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0889 - root_mean_squared_error: 0.2981 - val_loss: 0.0859 - val_root_mean_squared_error: 0.2930\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0885 - root_mean_squared_error: 0.2975 - val_loss: 0.0856 - val_root_mean_squared_error: 0.2926\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0882 - root_mean_squared_error: 0.2970 - val_loss: 0.0854 - val_root_mean_squared_error: 0.2922\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0880 - root_mean_squared_error: 0.2966 - val_loss: 0.0852 - val_root_mean_squared_error: 0.2918\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0877 - root_mean_squared_error: 0.2962 - val_loss: 0.0850 - val_root_mean_squared_error: 0.2916\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0875 - root_mean_squared_error: 0.2958 - val_loss: 0.0849 - val_root_mean_squared_error: 0.2914\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0874 - root_mean_squared_error: 0.2956 - val_loss: 0.0848 - val_root_mean_squared_error: 0.2913\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0872 - root_mean_squared_error: 0.2953 - val_loss: 0.0847 - val_root_mean_squared_error: 0.2910\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0871 - root_mean_squared_error: 0.2951 - val_loss: 0.0846 - val_root_mean_squared_error: 0.2909\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0869 - root_mean_squared_error: 0.2949 - val_loss: 0.0846 - val_root_mean_squared_error: 0.2908\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0868 - root_mean_squared_error: 0.2947 - val_loss: 0.0845 - val_root_mean_squared_error: 0.2907\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0867 - root_mean_squared_error: 0.2945 - val_loss: 0.0845 - val_root_mean_squared_error: 0.2907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9fe3ebbe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ajwHETx6Mw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6f236429-f9d1-4d7a-91a3-0f99da9fc47c"
      },
      "source": [
        "preds = model.predict(X_valid).reshape(-1)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100) for input Tensor(\"input_11:0\", shape=(None, 100), dtype=float32), but it was called on an input with incompatible shape (None, 1403).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxZ_sdI495Kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "6e64ca12-9714-4bcb-8f32-2fcf9033e644"
      },
      "source": [
        "print(classification_report(y_valid, (preds > 0.5).astype(int)))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95       453\n",
            "           1       0.00      0.00      0.00        47\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.45      0.50      0.48       500\n",
            "weighted avg       0.82      0.91      0.86       500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7zlb8j096DZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Тоже плохо. \n",
        "# Результат почти каждого пункта моей работы мне не нравится, но я уже рискую пропустить дедлайн.\n",
        "\n",
        "# Огромное спасибо за курс!"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}