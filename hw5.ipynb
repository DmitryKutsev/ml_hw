{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled32.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMKiqT+Q92BILDaKhC6X1HA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/ml_hw/blob/master/hw5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH6Ucdg1MNBO",
        "colab_type": "code",
        "outputId": "873b402d-3562-4410-8289-1d8d7c5caaab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/TatianaShavrina/hse_ml_m1/master/ensembles/complaints.csv"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-09 20:54:04--  https://raw.githubusercontent.com/TatianaShavrina/hse_ml_m1/master/ensembles/complaints.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4148456 (4.0M) [text/plain]\n",
            "Saving to: ‘complaints.csv’\n",
            "\n",
            "\rcomplaints.csv        0%[                    ]       0  --.-KB/s               \rcomplaints.csv      100%[===================>]   3.96M  19.9MB/s    in 0.2s    \n",
            "\n",
            "2020-04-09 20:54:06 (19.9 MB/s) - ‘complaints.csv’ saved [4148456/4148456]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2La_iwKrMSqz",
        "colab_type": "code",
        "outputId": "76f68483-a7e6-45d4-dac9-ff42fdff8c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!pip install pymorphy2[fast]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 798kB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 3.3MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting DAWG>=0.7.3; extra == \"fast\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/ef/91b619a399685f7a0a95a03628006ba814d96293bbbbed234ee66fbdefd9/DAWG-0.8.0.tar.gz (371kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 27.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.8.0-cp36-cp36m-linux_x86_64.whl size=859603 sha256=8d6f141be5f48d249a13e4c25cfabe857cd3ff0718e32f92af94d3cec079110d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/1f/f0/a5b1f9d02e193c997d252c33d215f24dfd7a448bc0166b2a12\n",
            "Successfully built DAWG\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.8.0 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyNyiRsGMUnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.metrics import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression, LinearRegression, LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier,  BaggingClassifier, BaggingRegressor, RandomTreesEmbedding,GradientBoostingClassifier\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from nltk import word_tokenize\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX_KyefjMXqZ",
        "colab_type": "code",
        "outputId": "2a40df46-648b-488d-90d2-0d8e9d39a835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "data = pd.read_csv('complaints.csv', sep='\\t')\n",
        "print(data.head(10))\n",
        "y = data[\"PRODUCT_ID\"]\n",
        "X = data[\"cleaned_text\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   COMPLAINT_ID  ...                                       cleaned_text\n",
            "0       3178905  ...  go year . contact advis never took loan . advi...\n",
            "1       3175952  ...  mail valid debt xx/xx/19 valid receiv , receiv...\n",
            "2       3174747  ...  xx/xx/xxxx appli receiv onlin loan bluechip fi...\n",
            "3       3173291  ...  xx/xx/xxxx appli receiv onlin loan . loan amou...\n",
            "4       3172221  ...  told husband left bill . debt would pay within...\n",
            "5       3172723  ...  payday loan , becam abl pay . everyon famili c...\n",
            "6       3171497  ...  within past week , contact oracl financi group...\n",
            "7       3171674  ...  call work said courthous owe money . got phone...\n",
            "8       3170784  ...  today xx/xx/xxxx cst contact ks . receiv appro...\n",
            "9       3171479  ...  cashcal attempt collect fraudul debt . ident s...\n",
            "\n",
            "[10 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmEplcJWMbdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.preprocessing import FunctionTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fjwR8c0vpp7",
        "colab_type": "code",
        "outputId": "d306b10b-b2c6-42a0-9052-b83edbe8e2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCBAE53nMdZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "cfb25673-9329-440a-8a3e-78bc3d1695a9"
      },
      "source": [
        "clf1 = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=3)\n",
        "clf2 = RandomForestClassifier(n_estimators=250, random_state=3)\n",
        "clf3 = GaussianNB()\n",
        "clf4 = SVC(class_weight=\"balanced\", random_state =30)\n",
        "eclf = VotingClassifier(estimators=[\n",
        "        ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('svc', clf4)], voting='hard')\n",
        "\n",
        "voting = Pipeline([\n",
        "    ('vect', CountVectorizer( analyzer='word', max_features=360, ngram_range=(1,1))),\n",
        "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "    ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
        "    ('reducer', TruncatedSVD(n_components=120)),\n",
        "    ('clf', eclf),\n",
        "    ])\n",
        "voting = voting.fit(X_train, y_train)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyR508oJMm76",
        "colab_type": "code",
        "outputId": "a95057d5-e170-4841-afde-dcf4d6f360e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "predictions = voting.predict(X_test)\n",
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.70\n",
            "Recall:   0.69\n",
            "F1-measure:   0.69\n",
            "Accuracy:   0.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02yveQxqR-wG",
        "colab_type": "text"
      },
      "source": [
        "Почти 70, посмотрим теперь bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yot0jgFQ4pE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import BaggingClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-73XN6ECz37Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
        "clf2 = KNeighborsClassifier(n_neighbors=1)    \n",
        "\n",
        "bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=20, max_samples=0.8, max_features=0.8)\n",
        "bagging2 = BaggingClassifier(base_estimator=clf2, n_estimators=20, max_samples=0.8, max_features=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugUyW7606Kcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bag = Pipeline([\n",
        "    ('vect', CountVectorizer( analyzer='word', max_features=360, ngram_range=(1,1))),\n",
        "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "    ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
        "    ('reducer', TruncatedSVD(n_components=120)),\n",
        "    ('clf', bagging1),\n",
        "    ])\n",
        "bag = bag.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K5hd-Fs0tb3",
        "colab_type": "code",
        "outputId": "3cabbb75-1858-4b6c-ea03-349cd4f874a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "predictions = bag.predict(X_test)\n",
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.20\n",
            "Recall:   0.36\n",
            "F1-measure:   0.21\n",
            "Accuracy:   0.37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db7xH0b92PYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bag2 = Pipeline([\n",
        "    ('vect', CountVectorizer( analyzer='word', max_features=360, ngram_range=(1,1))),\n",
        "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "    ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
        "    ('reducer', TruncatedSVD(n_components=200)),\n",
        "    ('clf', bagging2),\n",
        "    ])\n",
        "bag2 = bag2.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRBg4Y2yzFVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "835751cd-b408-4e68-eb58-1ff127f65496"
      },
      "source": [
        "predictions = bag2.predict(X_test)\n",
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.63\n",
            "Recall:   0.63\n",
            "F1-measure:   0.63\n",
            "Accuracy:   0.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH6V2Dbi1pWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Не очень много получилось, но может я не так что-то сделал. Теперь Boosting."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2wPmGmY4H5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFZYJYitj_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adb_clf = DecisionTreeClassifier(criterion='entropy', max_depth=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duh0wzhltsdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_est = [1, 2, 3, 10]\n",
        "label = ['AdaBoost (n_est=1)', 'AdaBoost (n_est=2)', 'AdaBoost (n_est=3)', 'AdaBoost (n_est=10)']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeIVM9eNt9SH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "boost = AdaBoostClassifier(base_estimator=adb_clf, n_estimators=n_est)\n",
        "boosting = Pipeline([\n",
        "('vect', CountVectorizer( analyzer='word', max_features=350, ngram_range=(1,1))),\n",
        "('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
        "('reducer', TruncatedSVD(n_components=200)),\n",
        "('clf', boost),\n",
        "])   \n",
        "boosting = boosting.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OntEWOuxUQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c50e92a3-8dd4-4b04-d69c-4907628fa457"
      },
      "source": [
        "predictions = boosting.predict(X_test)\n",
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.53\n",
            "Recall:   0.54\n",
            "F1-measure:   0.53\n",
            "Accuracy:   0.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbMYrdB7yzJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Тоже плохо, и теперь Stacking."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60OKDSfn1Ybn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mlxtend.classifier import StackingClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcinCe3z1ef1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
        "clf3 = GaussianNB()\n",
        "clf2 = RandomForestClassifier(n_estimators=200, random_state=1)\n",
        "clf4 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
        "lr = LogisticRegression()\n",
        "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                          meta_classifier=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaBUI4J61jhr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "109e4795-69cf-4506-cb2a-26168530cd46"
      },
      "source": [
        "stacking_pipe = Pipeline([\n",
        "('vect', CountVectorizer(analyzer='word', max_features=300, ngram_range=(1,1))),\n",
        "('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
        "('reducer', TruncatedSVD(n_components=200)),\n",
        "('clf', sclf),\n",
        "])   \n",
        "stacking = stacking_pipe.fit(X_train, y_train)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8nNMpwf1-Jt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "df25dcfa-3d30-46a0-a8e9-b6624ea2e37e"
      },
      "source": [
        "predictions = stacking.predict(X_test)\n",
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.37\n",
            "Recall:   0.43\n",
            "F1-measure:   0.38\n",
            "Accuracy:   0.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGx9GyJb2EAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = KNeighborsClassifier(n_neighbors=1, leaf_size=35)\n",
        "clf2 = RandomForestClassifier(random_state=1, min_samples_leaf=1)\n",
        "clf3 = GaussianNB()\n",
        "lr = LogisticRegression()\n",
        "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
        "                          meta_classifier=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDs3Is6L6Ol5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "33930b9b-cf5f-470a-b31d-a0b52382e4ee"
      },
      "source": [
        "stacking_pipe = Pipeline([\n",
        "('vect', CountVectorizer(analyzer='word', max_features=350, ngram_range=(1,1))),\n",
        "('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
        "('reducer', TruncatedSVD(n_components=300)),\n",
        "('clf', sclf),\n",
        "])   \n",
        "stacking = stacking_pipe.fit(X_train, y_train)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvGgDIfM6Ud9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c5d11be8-f345-41e7-a1ac-6d2684bdcbfc"
      },
      "source": [
        "predictions = stacking.predict(X_test)\n",
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.58\n",
            "Recall:   0.57\n",
            "F1-measure:   0.57\n",
            "Accuracy:   0.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYAymrBk6U1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Тоже не очень, хотя вроде я попробовал разные параметры.Получается, что лучше всех сработал VotingClassifier."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOLpGmbk8ZrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}