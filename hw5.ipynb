{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled32.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLmw7raaD0kW2iOLWvy9W3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/ml_hw/blob/master/hw5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH6Ucdg1MNBO",
        "colab_type": "code",
        "outputId": "2327309d-8ad2-40f1-93fc-e9df34b5e44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/TatianaShavrina/hse_ml_m1/master/ensembles/complaints.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-08 16:45:58--  https://raw.githubusercontent.com/TatianaShavrina/hse_ml_m1/master/ensembles/complaints.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4148456 (4.0M) [text/plain]\n",
            "Saving to: ‘complaints.csv’\n",
            "\n",
            "\rcomplaints.csv        0%[                    ]       0  --.-KB/s               \rcomplaints.csv      100%[===================>]   3.96M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-04-08 16:45:58 (58.3 MB/s) - ‘complaints.csv’ saved [4148456/4148456]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2La_iwKrMSqz",
        "colab_type": "code",
        "outputId": "bcd6f338-8ad2-47aa-ac40-b44a6a4d03fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!pip install pymorphy2[fast]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████                         | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 6.3MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting DAWG>=0.7.3; extra == \"fast\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/ef/91b619a399685f7a0a95a03628006ba814d96293bbbbed234ee66fbdefd9/DAWG-0.8.0.tar.gz (371kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 46.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.8.0-cp36-cp36m-linux_x86_64.whl size=859632 sha256=75f5cebe6d92e48da30b11f54218402c797cca5caf2d4b240d5fd3c97f6ece16\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/1f/f0/a5b1f9d02e193c997d252c33d215f24dfd7a448bc0166b2a12\n",
            "Successfully built DAWG\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.8.0 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyNyiRsGMUnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.metrics import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression, LinearRegression, LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier,  BaggingClassifier, BaggingRegressor, RandomTreesEmbedding,GradientBoostingClassifier\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from nltk import word_tokenize\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX_KyefjMXqZ",
        "colab_type": "code",
        "outputId": "d41906ee-acc3-4f11-d630-45c9c7ee9c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "data = pd.read_csv('complaints.csv', sep='\\t')\n",
        "print(data.head(10))\n",
        "y = data[\"PRODUCT_ID\"]\n",
        "X = data[\"cleaned_text\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   COMPLAINT_ID  ...                                       cleaned_text\n",
            "0       3178905  ...  go year . contact advis never took loan . advi...\n",
            "1       3175952  ...  mail valid debt xx/xx/19 valid receiv , receiv...\n",
            "2       3174747  ...  xx/xx/xxxx appli receiv onlin loan bluechip fi...\n",
            "3       3173291  ...  xx/xx/xxxx appli receiv onlin loan . loan amou...\n",
            "4       3172221  ...  told husband left bill . debt would pay within...\n",
            "5       3172723  ...  payday loan , becam abl pay . everyon famili c...\n",
            "6       3171497  ...  within past week , contact oracl financi group...\n",
            "7       3171674  ...  call work said courthous owe money . got phone...\n",
            "8       3170784  ...  today xx/xx/xxxx cst contact ks . receiv appro...\n",
            "9       3171479  ...  cashcal attempt collect fraudul debt . ident s...\n",
            "\n",
            "[10 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmEplcJWMbdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.preprocessing import FunctionTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fjwR8c0vpp7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d33419e5-b128-4644-9c58-b5eb2f0eaf73"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCBAE53nMdZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=3)\n",
        "clf2 = RandomForestClassifier(n_estimators=250, random_state=3)\n",
        "clf3 = GaussianNB()\n",
        "clf4 = SVC(class_weight=\"balanced\", random_state =30)\n",
        "eclf = VotingClassifier(estimators=[\n",
        "        ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('svc', clf4)], voting='hard')\n",
        "\n",
        "voting = Pipeline([\n",
        "    ('vect', CountVectorizer( analyzer='word', max_features=360, ngram_range=(1,1))),\n",
        "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "    ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
        "    ('reducer', TruncatedSVD(n_components=120)),\n",
        "    ('clf', eclf),\n",
        "    ])\n",
        "voting = voting.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyR508oJMm76",
        "colab_type": "code",
        "outputId": "fcf9d079-eb5d-4795-ce8c-348288155c2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "predictions = voting.predict(X_test)\n",
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.70\n",
            "Recall:   0.69\n",
            "F1-measure:   0.69\n",
            "Accuracy:   0.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02yveQxqR-wG",
        "colab_type": "text"
      },
      "source": [
        "Почти 70, посмотрим теперь bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i2ne0mAMooV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import itertools\n",
        "# import numpy as np\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "#np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yot0jgFQ4pE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %matplotlib inline\n",
        "\n",
        "# import itertools\n",
        "# import numpy as np\n",
        "\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.gridspec as gridspec\n",
        "\n",
        "# from sklearn import datasets\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# from sklearn.ensemble import BaggingClassifier\n",
        "# from sklearn.model_selection import cross_val_score, train_test_split\n",
        "\n",
        "# from mlxtend.plotting import plot_learning_curves\n",
        "# from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "# np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-73XN6ECz37Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    \n",
        "clf1 = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
        "clf2 = KNeighborsClassifier(n_neighbors=1)    \n",
        "\n",
        "#bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
        "bagging2 = BaggingClassifier(base_estimator=clf2, n_estimators=100, max_samples=0.8, max_features=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugUyW7606Kcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bag = Pipeline([\n",
        "    ('vect', CountVectorizer( analyzer='word', max_features=360, ngram_range=(1,1))),\n",
        "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "    ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
        "    ('reducer', TruncatedSVD(n_components=120)),\n",
        "    ('clf', bagging2),\n",
        "    ])\n",
        "bag = bag.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K5hd-Fs0tb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8928d199-bf79-4569-bcf9-655876438321"
      },
      "source": [
        "predictions = bag.predict(X_test)\n",
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.63\n",
            "Recall:   0.63\n",
            "F1-measure:   0.62\n",
            "Accuracy:   0.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db7xH0b92PYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}